{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d155084",
   "metadata": {},
   "source": [
    "## Load model from checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5220147b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import time\n",
    "from datetime import datetime\n",
    "import os\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5504c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKPOINT_PATH = \"checkpoints_2025-07-31_21-51-51/autoencoder_epoch500.pt\"  # Example checkpoint directory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b440275b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(path, model, optimizer, scheduler, device):\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"‚ùå Checkpoint not found: {path}\")\n",
    "        return 0, [], []\n",
    "\n",
    "    print(f\"üîÑ Loading checkpoint from: {path}\")\n",
    "    checkpoint = torch.load(path, map_location=device)\n",
    "\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "    if 'scheduler_state_dict' in checkpoint:\n",
    "        scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "\n",
    "    epoch = checkpoint.get('epoch', 0) + 1\n",
    "    train_losses = checkpoint.get('train_losses', [])\n",
    "    test_losses = checkpoint.get('test_losses', [])\n",
    "\n",
    "    print(f\"‚úÖ Resumed from epoch {epoch}\")\n",
    "    return epoch, train_losses, test_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be1fce2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TitanicAutoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, latent_dim=4):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, latent_dim)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, input_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)       # compressed embedding\n",
    "        x_recon = self.decoder(z) # reconstructed input\n",
    "        return x_recon\n",
    "\n",
    "    def encode(self, x):\n",
    "        return self.encoder(x)    # get embedding only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2305fe0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = 10\n",
    "LATENT_DIM = 8\n",
    "model = TitanicAutoencoder(input_dim=INPUT_DIM, latent_dim=LATENT_DIM).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa4b1b98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Loading checkpoint from: checkpoints_2025-07-31_21-51-51/autoencoder_epoch500.pt\n",
      "‚úÖ Resumed from epoch 500\n"
     ]
    }
   ],
   "source": [
    "# Load the checkpoint\n",
    "start_epoch, train_losses, test_losses = load_checkpoint(\n",
    "    CHECKPOINT_PATH, model, optimizer, scheduler, device\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27b05ef",
   "metadata": {},
   "source": [
    "## Load training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81043d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sns.load_dataset(\"titanic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2efc732c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training DataFrame: (713, 15)\n",
      "Shape of test DataFrame: (178, 15)\n"
     ]
    }
   ],
   "source": [
    "## Randomly select a fraction of the dataset\n",
    "FRACTION = 0.8\n",
    "\n",
    "train_df = df.sample(frac=FRACTION, random_state=42) # fix seed for reproducibility\n",
    "# Get the remaining 20% of rows for the test set\n",
    "# This is achieved by selecting rows whose index is not present in the training set\n",
    "test_df = df.drop(train_df.index)\n",
    "# Display the shapes of the resulting DataFrames\n",
    "print(f\"Shape of training DataFrame: {train_df.shape}\")\n",
    "print(f\"Shape of test DataFrame: {test_df.shape}\")\n",
    "\n",
    "# You can now save these DataFrames if needed\n",
    "train_df.to_csv('train_data.csv', index=False)\n",
    "test_df.to_csv('test_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2fd630dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Drop columns with missing value and alive column\n",
    "df_nomissing = df.drop(columns=['age', 'deck', 'embarked', 'embark_town', 'survived',])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3722683",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize numeric feature\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "num_cols = [\"fare\", \"sibsp\", \"parch\"]\n",
    "scaler = StandardScaler()\n",
    "df_nomissing[num_cols] = scaler.fit_transform(df_nomissing[num_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "28e9b14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert categorial features to integers using Label Encoding\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "cat_cols = [\"pclass\", \"sex\", \"class\", \"who\", \"adult_male\", \"alive\", \"alone\"]  # treat pclass as categorical\n",
    "label_encoders = {}\n",
    "\n",
    "for col in cat_cols:\n",
    "    le = LabelEncoder()\n",
    "    df_nomissing[col] = le.fit_transform(df_nomissing[col])\n",
    "    label_encoders[col] = le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a0f070e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training DataFrame: (713, 10)\n",
      "Shape of test DataFrame: (178, 10)\n"
     ]
    }
   ],
   "source": [
    "## Randomly select a fraction of the dataset\n",
    "FRACTION = 0.8\n",
    "\n",
    "train_df_nomissing = df_nomissing.sample(frac=FRACTION, random_state=42) # fix seed for reproducibility\n",
    "# Get the remaining 20% of rows for the test set\n",
    "# This is achieved by selecting rows whose index is not present in the training set\n",
    "test_df_nomissing = df_nomissing.drop(train_df_nomissing.index)\n",
    "# Display the shapes of the resulting DataFrames\n",
    "print(f\"Shape of training DataFrame: {train_df_nomissing.shape}\")\n",
    "print(f\"Shape of test DataFrame: {test_df_nomissing.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d47d8188",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df_nomissing.values.astype(\"float32\")\n",
    "X_test = test_df_nomissing.values.astype(\"float32\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4430dc37",
   "metadata": {},
   "source": [
    "## Pytorch dataset for loading data to training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8a452aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class TitanicAutoencoderDataset(Dataset):\n",
    "    def __init__(self, X):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.X[idx]  # input = target\n",
    "\n",
    "train_ds = TitanicAutoencoderDataset(X_train)\n",
    "test_ds = TitanicAutoencoderDataset(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b08adb4",
   "metadata": {},
   "source": [
    "## Get GPU utilization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "38b10dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "def get_gpu_utilization():\n",
    "    result = subprocess.run(\n",
    "        ['nvidia-smi', '--query-gpu=utilization.gpu,memory.used',\n",
    "         '--format=csv,nounits,noheader'],\n",
    "        stdout=subprocess.PIPE,\n",
    "        text=True\n",
    "    )\n",
    "    gpu_util, mem_used = map(int, result.stdout.strip().split(','))\n",
    "    return gpu_util, mem_used"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa06bd7",
   "metadata": {},
   "source": [
    "## Training starts from checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bc015abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a timestamped run directory\n",
    "os.makedirs(\"runs-start-from-checkpoint\", exist_ok=True) # Create directories for logs and checkpoints\n",
    "RUN_NAME = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "LOG_DIR = f\"runs-checkpoint/autoencoder_{RUN_NAME}\" # Create directories for logs and checkpoints\n",
    "CHECKPOINT_DIR = f\"ckpt_checkpoints_{RUN_NAME}\" # Create directories for logs and checkpoints\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True) # Create directories if they don't exist\n",
    "BATCH_SIZE = 256 # Adjust batch size as needed\n",
    "WORKERS = 1 # Number of workers for DataLoader, adjust based on your system\n",
    "\n",
    "writer = SummaryWriter(log_dir=LOG_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8c8193f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d7266f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_curve(train_losses, test_losses):\n",
    "    fig, ax = plt.subplots(figsize=(8, 5))\n",
    "    ax.plot(train_losses, label=\"Train Loss\", marker='o')\n",
    "    ax.plot(test_losses, label=\"Test Loss\", marker='x')\n",
    "    ax.set_xlabel(\"Epoch\")\n",
    "    ax.set_ylabel(\"Loss\")\n",
    "    ax.set_title(\"Train vs Test Loss\")\n",
    "    ax.legend()\n",
    "    ax.grid(True)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "55a10236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 501 | Train Loss: 0.0028 | Test Loss: 0.0025 | LR: 0.001000 | Time: 0.17 sec\n",
      "New best model found at epoch 501, saving checkpoint...\n",
      "Epoch 502 | Train Loss: 0.0028 | Test Loss: 0.0025 | LR: 0.001000 | Time: 0.05 sec\n",
      "New best model found at epoch 502, saving checkpoint...\n",
      "Epoch 503 | Train Loss: 0.0028 | Test Loss: 0.0025 | LR: 0.001000 | Time: 0.05 sec\n",
      "New best model found at epoch 503, saving checkpoint...\n",
      "Epoch 504 | Train Loss: 0.0028 | Test Loss: 0.0025 | LR: 0.001000 | Time: 0.05 sec\n",
      "New best model found at epoch 504, saving checkpoint...\n",
      "Epoch 505 | Train Loss: 0.0027 | Test Loss: 0.0025 | LR: 0.001000 | Time: 0.05 sec\n",
      "New best model found at epoch 505, saving checkpoint...\n",
      "Epoch 506 | Train Loss: 0.0028 | Test Loss: 0.0025 | LR: 0.001000 | Time: 0.05 sec\n",
      "New best model found at epoch 506, saving checkpoint...\n",
      "Epoch 507 | Train Loss: 0.0027 | Test Loss: 0.0025 | LR: 0.001000 | Time: 0.05 sec\n",
      "New best model found at epoch 507, saving checkpoint...\n",
      "Epoch 508 | Train Loss: 0.0028 | Test Loss: 0.0025 | LR: 0.001000 | Time: 0.05 sec\n",
      "New best model found at epoch 508, saving checkpoint...\n",
      "Epoch 509 | Train Loss: 0.0028 | Test Loss: 0.0025 | LR: 0.001000 | Time: 0.05 sec\n",
      "New best model found at epoch 509, saving checkpoint...\n",
      "Epoch 510 | Train Loss: 0.0027 | Test Loss: 0.0025 | LR: 0.001000 | Time: 0.05 sec\n",
      "New best model found at epoch 510, saving checkpoint...\n",
      "Epoch 511 | Train Loss: 0.0028 | Test Loss: 0.0025 | LR: 0.001000 | Time: 0.05 sec\n",
      "New best model found at epoch 511, saving checkpoint...\n",
      "Epoch 512 | Train Loss: 0.0027 | Test Loss: 0.0024 | LR: 0.001000 | Time: 0.05 sec\n",
      "New best model found at epoch 512, saving checkpoint...\n",
      "Epoch 513 | Train Loss: 0.0027 | Test Loss: 0.0024 | LR: 0.001000 | Time: 0.05 sec\n",
      "New best model found at epoch 513, saving checkpoint...\n",
      "Epoch 514 | Train Loss: 0.0027 | Test Loss: 0.0024 | LR: 0.001000 | Time: 0.05 sec\n",
      "New best model found at epoch 514, saving checkpoint...\n",
      "Epoch 515 | Train Loss: 0.0027 | Test Loss: 0.0024 | LR: 0.001000 | Time: 0.05 sec\n",
      "New best model found at epoch 515, saving checkpoint...\n",
      "Epoch 516 | Train Loss: 0.0027 | Test Loss: 0.0024 | LR: 0.001000 | Time: 0.05 sec\n",
      "New best model found at epoch 516, saving checkpoint...\n",
      "Epoch 517 | Train Loss: 0.0027 | Test Loss: 0.0024 | LR: 0.001000 | Time: 0.05 sec\n",
      "New best model found at epoch 517, saving checkpoint...\n",
      "Epoch 518 | Train Loss: 0.0027 | Test Loss: 0.0024 | LR: 0.001000 | Time: 0.05 sec\n",
      "New best model found at epoch 518, saving checkpoint...\n",
      "Epoch 519 | Train Loss: 0.0027 | Test Loss: 0.0024 | LR: 0.001000 | Time: 0.05 sec\n",
      "New best model found at epoch 519, saving checkpoint...\n",
      "Epoch 520 | Train Loss: 0.0026 | Test Loss: 0.0024 | LR: 0.001000 | Time: 0.05 sec\n",
      "New best model found at epoch 520, saving checkpoint...\n",
      "Epoch 521 | Train Loss: 0.0026 | Test Loss: 0.0024 | LR: 0.001000 | Time: 0.05 sec\n",
      "New best model found at epoch 521, saving checkpoint...\n",
      "Epoch 522 | Train Loss: 0.0026 | Test Loss: 0.0024 | LR: 0.001000 | Time: 0.05 sec\n",
      "New best model found at epoch 522, saving checkpoint...\n",
      "Epoch 523 | Train Loss: 0.0026 | Test Loss: 0.0024 | LR: 0.001000 | Time: 0.05 sec\n",
      "Epoch 524 | Train Loss: 0.0026 | Test Loss: 0.0023 | LR: 0.001000 | Time: 0.05 sec\n",
      "New best model found at epoch 524, saving checkpoint...\n",
      "Epoch 525 | Train Loss: 0.0026 | Test Loss: 0.0023 | LR: 0.001000 | Time: 0.05 sec\n",
      "New best model found at epoch 525, saving checkpoint...\n",
      "Epoch 526 | Train Loss: 0.0026 | Test Loss: 0.0023 | LR: 0.001000 | Time: 0.05 sec\n",
      "New best model found at epoch 526, saving checkpoint...\n",
      "Epoch 527 | Train Loss: 0.0026 | Test Loss: 0.0023 | LR: 0.001000 | Time: 0.05 sec\n",
      "New best model found at epoch 527, saving checkpoint...\n",
      "Epoch 528 | Train Loss: 0.0026 | Test Loss: 0.0023 | LR: 0.001000 | Time: 0.05 sec\n",
      "New best model found at epoch 528, saving checkpoint...\n",
      "Epoch 529 | Train Loss: 0.0025 | Test Loss: 0.0023 | LR: 0.001000 | Time: 0.05 sec\n",
      "New best model found at epoch 529, saving checkpoint...\n",
      "Epoch 530 | Train Loss: 0.0025 | Test Loss: 0.0023 | LR: 0.001000 | Time: 0.05 sec\n",
      "New best model found at epoch 530, saving checkpoint...\n",
      "Epoch 531 | Train Loss: 0.0025 | Test Loss: 0.0023 | LR: 0.001000 | Time: 0.05 sec\n",
      "New best model found at epoch 531, saving checkpoint...\n",
      "Epoch 532 | Train Loss: 0.0025 | Test Loss: 0.0023 | LR: 0.001000 | Time: 0.06 sec\n",
      "New best model found at epoch 532, saving checkpoint...\n",
      "Epoch 533 | Train Loss: 0.0026 | Test Loss: 0.0023 | LR: 0.001000 | Time: 0.06 sec\n",
      "New best model found at epoch 533, saving checkpoint...\n",
      "Epoch 534 | Train Loss: 0.0025 | Test Loss: 0.0023 | LR: 0.001000 | Time: 0.05 sec\n",
      "New best model found at epoch 534, saving checkpoint...\n",
      "Epoch 535 | Train Loss: 0.0025 | Test Loss: 0.0022 | LR: 0.001000 | Time: 0.05 sec\n",
      "New best model found at epoch 535, saving checkpoint...\n",
      "Epoch 536 | Train Loss: 0.0025 | Test Loss: 0.0022 | LR: 0.001000 | Time: 0.05 sec\n",
      "New best model found at epoch 536, saving checkpoint...\n",
      "Epoch 537 | Train Loss: 0.0025 | Test Loss: 0.0022 | LR: 0.001000 | Time: 0.05 sec\n",
      "New best model found at epoch 537, saving checkpoint...\n",
      "Epoch 538 | Train Loss: 0.0025 | Test Loss: 0.0022 | LR: 0.001000 | Time: 0.06 sec\n",
      "New best model found at epoch 538, saving checkpoint...\n",
      "Epoch 539 | Train Loss: 0.0025 | Test Loss: 0.0022 | LR: 0.001000 | Time: 0.05 sec\n",
      "New best model found at epoch 539, saving checkpoint...\n",
      "Epoch 540 | Train Loss: 0.0025 | Test Loss: 0.0022 | LR: 0.001000 | Time: 0.06 sec\n",
      "New best model found at epoch 540, saving checkpoint...\n",
      "Epoch 541 | Train Loss: 0.0024 | Test Loss: 0.0022 | LR: 0.001000 | Time: 0.05 sec\n",
      "New best model found at epoch 541, saving checkpoint...\n",
      "Epoch 542 | Train Loss: 0.0024 | Test Loss: 0.0022 | LR: 0.001000 | Time: 0.19 sec\n",
      "New best model found at epoch 542, saving checkpoint...\n",
      "Epoch 543 | Train Loss: 0.0024 | Test Loss: 0.0022 | LR: 0.001000 | Time: 0.05 sec\n",
      "New best model found at epoch 543, saving checkpoint...\n",
      "Epoch 544 | Train Loss: 0.0025 | Test Loss: 0.0022 | LR: 0.001000 | Time: 0.05 sec\n",
      "New best model found at epoch 544, saving checkpoint...\n",
      "Epoch 545 | Train Loss: 0.0024 | Test Loss: 0.0022 | LR: 0.001000 | Time: 0.05 sec\n",
      "New best model found at epoch 545, saving checkpoint...\n",
      "Epoch 546 | Train Loss: 0.0024 | Test Loss: 0.0022 | LR: 0.001000 | Time: 0.05 sec\n",
      "New best model found at epoch 546, saving checkpoint...\n",
      "Epoch 547 | Train Loss: 0.0024 | Test Loss: 0.0022 | LR: 0.001000 | Time: 0.05 sec\n",
      "New best model found at epoch 547, saving checkpoint...\n",
      "Epoch 548 | Train Loss: 0.0024 | Test Loss: 0.0022 | LR: 0.001000 | Time: 0.05 sec\n",
      "New best model found at epoch 548, saving checkpoint...\n",
      "Epoch 549 | Train Loss: 0.0024 | Test Loss: 0.0021 | LR: 0.001000 | Time: 0.05 sec\n",
      "New best model found at epoch 549, saving checkpoint...\n",
      "Epoch 550 | Train Loss: 0.0024 | Test Loss: 0.0021 | LR: 0.001000 | Time: 0.05 sec\n",
      "New best model found at epoch 550, saving checkpoint...\n",
      "Epoch 551 | Train Loss: 0.0024 | Test Loss: 0.0021 | LR: 0.001000 | Time: 0.05 sec\n",
      "New best model found at epoch 551, saving checkpoint...\n",
      "Epoch 552 | Train Loss: 0.0024 | Test Loss: 0.0021 | LR: 0.001000 | Time: 0.05 sec\n",
      "New best model found at epoch 552, saving checkpoint...\n",
      "Epoch 553 | Train Loss: 0.0024 | Test Loss: 0.0021 | LR: 0.001000 | Time: 0.05 sec\n",
      "New best model found at epoch 553, saving checkpoint...\n",
      "Epoch 554 | Train Loss: 0.0023 | Test Loss: 0.0021 | LR: 0.001000 | Time: 0.05 sec\n",
      "New best model found at epoch 554, saving checkpoint...\n",
      "Epoch 555 | Train Loss: 0.0023 | Test Loss: 0.0021 | LR: 0.001000 | Time: 0.06 sec\n",
      "New best model found at epoch 555, saving checkpoint...\n",
      "Epoch 556 | Train Loss: 0.0023 | Test Loss: 0.0021 | LR: 0.001000 | Time: 0.05 sec\n",
      "New best model found at epoch 556, saving checkpoint...\n",
      "Epoch 557 | Train Loss: 0.0023 | Test Loss: 0.0021 | LR: 0.001000 | Time: 0.05 sec\n",
      "New best model found at epoch 557, saving checkpoint...\n",
      "Epoch 558 | Train Loss: 0.0024 | Test Loss: 0.0021 | LR: 0.001000 | Time: 0.06 sec\n",
      "New best model found at epoch 558, saving checkpoint...\n",
      "Epoch 559 | Train Loss: 0.0023 | Test Loss: 0.0021 | LR: 0.001000 | Time: 0.05 sec\n",
      "New best model found at epoch 559, saving checkpoint...\n",
      "Epoch 560 | Train Loss: 0.0023 | Test Loss: 0.0021 | LR: 0.001000 | Time: 0.06 sec\n",
      "New best model found at epoch 560, saving checkpoint...\n",
      "Epoch 561 | Train Loss: 0.0023 | Test Loss: 0.0021 | LR: 0.001000 | Time: 0.05 sec\n",
      "New best model found at epoch 561, saving checkpoint...\n",
      "Epoch 562 | Train Loss: 0.0024 | Test Loss: 0.0021 | LR: 0.001000 | Time: 0.05 sec\n",
      "New best model found at epoch 562, saving checkpoint...\n",
      "Epoch 563 | Train Loss: 0.0023 | Test Loss: 0.0021 | LR: 0.001000 | Time: 0.06 sec\n",
      "New best model found at epoch 563, saving checkpoint...\n",
      "Epoch 564 | Train Loss: 0.0023 | Test Loss: 0.0020 | LR: 0.001000 | Time: 0.05 sec\n",
      "New best model found at epoch 564, saving checkpoint...\n",
      "Epoch 565 | Train Loss: 0.0023 | Test Loss: 0.0020 | LR: 0.001000 | Time: 0.05 sec\n",
      "New best model found at epoch 565, saving checkpoint...\n",
      "Epoch 566 | Train Loss: 0.0023 | Test Loss: 0.0020 | LR: 0.001000 | Time: 0.05 sec\n",
      "New best model found at epoch 566, saving checkpoint...\n",
      "Epoch 567 | Train Loss: 0.0023 | Test Loss: 0.0020 | LR: 0.001000 | Time: 0.06 sec\n",
      "New best model found at epoch 567, saving checkpoint...\n",
      "Epoch 568 | Train Loss: 0.0023 | Test Loss: 0.0020 | LR: 0.001000 | Time: 0.05 sec\n",
      "New best model found at epoch 568, saving checkpoint...\n",
      "Epoch 569 | Train Loss: 0.0023 | Test Loss: 0.0020 | LR: 0.001000 | Time: 0.05 sec\n",
      "New best model found at epoch 569, saving checkpoint...\n",
      "Epoch 570 | Train Loss: 0.0023 | Test Loss: 0.0020 | LR: 0.001000 | Time: 0.05 sec\n",
      "New best model found at epoch 570, saving checkpoint...\n",
      "Epoch 571 | Train Loss: 0.0023 | Test Loss: 0.0020 | LR: 0.001000 | Time: 0.05 sec\n",
      "New best model found at epoch 571, saving checkpoint...\n",
      "Epoch 572 | Train Loss: 0.0022 | Test Loss: 0.0020 | LR: 0.001000 | Time: 0.05 sec\n",
      "New best model found at epoch 572, saving checkpoint...\n",
      "Epoch 573 | Train Loss: 0.0022 | Test Loss: 0.0020 | LR: 0.001000 | Time: 0.05 sec\n",
      "New best model found at epoch 573, saving checkpoint...\n",
      "Epoch 574 | Train Loss: 0.0022 | Test Loss: 0.0020 | LR: 0.001000 | Time: 0.05 sec\n",
      "New best model found at epoch 574, saving checkpoint...\n",
      "Epoch 575 | Train Loss: 0.0022 | Test Loss: 0.0020 | LR: 0.001000 | Time: 0.05 sec\n",
      "New best model found at epoch 575, saving checkpoint...\n",
      "Epoch 576 | Train Loss: 0.0022 | Test Loss: 0.0020 | LR: 0.001000 | Time: 0.05 sec\n",
      "New best model found at epoch 576, saving checkpoint...\n",
      "Epoch 577 | Train Loss: 0.0022 | Test Loss: 0.0020 | LR: 0.001000 | Time: 0.05 sec\n",
      "New best model found at epoch 577, saving checkpoint...\n",
      "Epoch 578 | Train Loss: 0.0022 | Test Loss: 0.0020 | LR: 0.001000 | Time: 0.23 sec\n",
      "New best model found at epoch 578, saving checkpoint...\n",
      "Epoch 579 | Train Loss: 0.0022 | Test Loss: 0.0019 | LR: 0.001000 | Time: 0.05 sec\n",
      "New best model found at epoch 579, saving checkpoint...\n",
      "Epoch 580 | Train Loss: 0.0022 | Test Loss: 0.0019 | LR: 0.001000 | Time: 0.06 sec\n",
      "New best model found at epoch 580, saving checkpoint...\n",
      "Epoch 581 | Train Loss: 0.0022 | Test Loss: 0.0019 | LR: 0.001000 | Time: 0.06 sec\n",
      "New best model found at epoch 581, saving checkpoint...\n",
      "Epoch 582 | Train Loss: 0.0022 | Test Loss: 0.0019 | LR: 0.001000 | Time: 0.05 sec\n",
      "New best model found at epoch 582, saving checkpoint...\n",
      "Epoch 583 | Train Loss: 0.0022 | Test Loss: 0.0019 | LR: 0.001000 | Time: 0.06 sec\n",
      "New best model found at epoch 583, saving checkpoint...\n",
      "Epoch 584 | Train Loss: 0.0022 | Test Loss: 0.0019 | LR: 0.001000 | Time: 0.05 sec\n",
      "New best model found at epoch 584, saving checkpoint...\n",
      "Epoch 585 | Train Loss: 0.0022 | Test Loss: 0.0019 | LR: 0.001000 | Time: 0.05 sec\n",
      "New best model found at epoch 585, saving checkpoint...\n",
      "Epoch 586 | Train Loss: 0.0022 | Test Loss: 0.0019 | LR: 0.001000 | Time: 0.06 sec\n",
      "New best model found at epoch 586, saving checkpoint...\n",
      "Epoch 587 | Train Loss: 0.0021 | Test Loss: 0.0019 | LR: 0.001000 | Time: 0.05 sec\n",
      "New best model found at epoch 587, saving checkpoint...\n",
      "Epoch 588 | Train Loss: 0.0022 | Test Loss: 0.0019 | LR: 0.001000 | Time: 0.05 sec\n",
      "New best model found at epoch 588, saving checkpoint...\n",
      "Epoch 589 | Train Loss: 0.0022 | Test Loss: 0.0019 | LR: 0.001000 | Time: 0.05 sec\n",
      "New best model found at epoch 589, saving checkpoint...\n",
      "Epoch 590 | Train Loss: 0.0021 | Test Loss: 0.0019 | LR: 0.001000 | Time: 0.05 sec\n",
      "New best model found at epoch 590, saving checkpoint...\n",
      "Epoch 591 | Train Loss: 0.0021 | Test Loss: 0.0019 | LR: 0.001000 | Time: 0.06 sec\n",
      "New best model found at epoch 591, saving checkpoint...\n",
      "Epoch 592 | Train Loss: 0.0021 | Test Loss: 0.0019 | LR: 0.001000 | Time: 0.05 sec\n",
      "New best model found at epoch 592, saving checkpoint...\n",
      "Epoch 593 | Train Loss: 0.0021 | Test Loss: 0.0019 | LR: 0.001000 | Time: 0.05 sec\n",
      "New best model found at epoch 593, saving checkpoint...\n",
      "Epoch 594 | Train Loss: 0.0021 | Test Loss: 0.0019 | LR: 0.001000 | Time: 0.05 sec\n",
      "New best model found at epoch 594, saving checkpoint...\n",
      "Epoch 595 | Train Loss: 0.0021 | Test Loss: 0.0019 | LR: 0.001000 | Time: 0.06 sec\n",
      "New best model found at epoch 595, saving checkpoint...\n",
      "Epoch 596 | Train Loss: 0.0021 | Test Loss: 0.0019 | LR: 0.001000 | Time: 0.05 sec\n",
      "New best model found at epoch 596, saving checkpoint...\n",
      "Epoch 597 | Train Loss: 0.0021 | Test Loss: 0.0018 | LR: 0.001000 | Time: 0.05 sec\n",
      "New best model found at epoch 597, saving checkpoint...\n",
      "Epoch 598 | Train Loss: 0.0021 | Test Loss: 0.0018 | LR: 0.001000 | Time: 0.06 sec\n",
      "New best model found at epoch 598, saving checkpoint...\n",
      "Epoch 599 | Train Loss: 0.0021 | Test Loss: 0.0018 | LR: 0.001000 | Time: 0.05 sec\n",
      "New best model found at epoch 599, saving checkpoint...\n",
      "Epoch 600 | Train Loss: 0.0021 | Test Loss: 0.0018 | LR: 0.001000 | Time: 0.06 sec\n",
      "Epoch 601 | Train Loss: 0.0020 | Test Loss: 0.0018 | LR: 0.001000 | Time: 0.05 sec\n",
      "New best model found at epoch 601, saving checkpoint...\n",
      "Epoch 602 | Train Loss: 0.0020 | Test Loss: 0.0018 | LR: 0.001000 | Time: 0.06 sec\n",
      "New best model found at epoch 602, saving checkpoint...\n",
      "Epoch 603 | Train Loss: 0.0020 | Test Loss: 0.0018 | LR: 0.001000 | Time: 0.05 sec\n",
      "New best model found at epoch 603, saving checkpoint...\n",
      "Epoch 604 | Train Loss: 0.0020 | Test Loss: 0.0018 | LR: 0.001000 | Time: 0.06 sec\n",
      "New best model found at epoch 604, saving checkpoint...\n",
      "Epoch 605 | Train Loss: 0.0020 | Test Loss: 0.0018 | LR: 0.001000 | Time: 0.05 sec\n",
      "New best model found at epoch 605, saving checkpoint...\n",
      "Epoch 606 | Train Loss: 0.0020 | Test Loss: 0.0018 | LR: 0.001000 | Time: 0.05 sec\n",
      "New best model found at epoch 606, saving checkpoint...\n",
      "Epoch 607 | Train Loss: 0.0020 | Test Loss: 0.0018 | LR: 0.001000 | Time: 0.05 sec\n",
      "New best model found at epoch 607, saving checkpoint...\n",
      "Epoch 608 | Train Loss: 0.0020 | Test Loss: 0.0018 | LR: 0.001000 | Time: 0.06 sec\n",
      "New best model found at epoch 608, saving checkpoint...\n",
      "Epoch 609 | Train Loss: 0.0020 | Test Loss: 0.0018 | LR: 0.001000 | Time: 0.05 sec\n",
      "New best model found at epoch 609, saving checkpoint...\n",
      "Epoch 610 | Train Loss: 0.0020 | Test Loss: 0.0018 | LR: 0.001000 | Time: 0.06 sec\n",
      "New best model found at epoch 610, saving checkpoint...\n",
      "Epoch 611 | Train Loss: 0.0020 | Test Loss: 0.0018 | LR: 0.001000 | Time: 0.06 sec\n",
      "New best model found at epoch 611, saving checkpoint...\n",
      "Epoch 612 | Train Loss: 0.0020 | Test Loss: 0.0018 | LR: 0.001000 | Time: 0.06 sec\n",
      "New best model found at epoch 612, saving checkpoint...\n",
      "Epoch 613 | Train Loss: 0.0019 | Test Loss: 0.0018 | LR: 0.001000 | Time: 0.06 sec\n",
      "New best model found at epoch 613, saving checkpoint...\n",
      "Epoch 614 | Train Loss: 0.0020 | Test Loss: 0.0018 | LR: 0.001000 | Time: 0.06 sec\n",
      "New best model found at epoch 614, saving checkpoint...\n",
      "Epoch 615 | Train Loss: 0.0020 | Test Loss: 0.0018 | LR: 0.001000 | Time: 0.05 sec\n",
      "New best model found at epoch 615, saving checkpoint...\n",
      "Epoch 616 | Train Loss: 0.0020 | Test Loss: 0.0017 | LR: 0.001000 | Time: 0.06 sec\n",
      "New best model found at epoch 616, saving checkpoint...\n",
      "Epoch 617 | Train Loss: 0.0019 | Test Loss: 0.0017 | LR: 0.001000 | Time: 0.06 sec\n",
      "New best model found at epoch 617, saving checkpoint...\n",
      "Epoch 618 | Train Loss: 0.0019 | Test Loss: 0.0017 | LR: 0.001000 | Time: 0.06 sec\n",
      "New best model found at epoch 618, saving checkpoint...\n",
      "Epoch 619 | Train Loss: 0.0019 | Test Loss: 0.0017 | LR: 0.001000 | Time: 0.06 sec\n",
      "New best model found at epoch 619, saving checkpoint...\n",
      "Epoch 620 | Train Loss: 0.0019 | Test Loss: 0.0017 | LR: 0.001000 | Time: 0.06 sec\n",
      "New best model found at epoch 620, saving checkpoint...\n",
      "Epoch 621 | Train Loss: 0.0019 | Test Loss: 0.0017 | LR: 0.001000 | Time: 0.07 sec\n",
      "New best model found at epoch 621, saving checkpoint...\n",
      "Epoch 622 | Train Loss: 0.0019 | Test Loss: 0.0017 | LR: 0.001000 | Time: 0.06 sec\n",
      "New best model found at epoch 622, saving checkpoint...\n",
      "Epoch 623 | Train Loss: 0.0019 | Test Loss: 0.0017 | LR: 0.001000 | Time: 0.06 sec\n",
      "Epoch 624 | Train Loss: 0.0019 | Test Loss: 0.0017 | LR: 0.001000 | Time: 0.05 sec\n",
      "New best model found at epoch 624, saving checkpoint...\n",
      "Epoch 625 | Train Loss: 0.0019 | Test Loss: 0.0017 | LR: 0.001000 | Time: 0.06 sec\n",
      "New best model found at epoch 625, saving checkpoint...\n",
      "Epoch 626 | Train Loss: 0.0019 | Test Loss: 0.0017 | LR: 0.001000 | Time: 0.06 sec\n",
      "New best model found at epoch 626, saving checkpoint...\n",
      "Epoch 627 | Train Loss: 0.0019 | Test Loss: 0.0017 | LR: 0.001000 | Time: 0.06 sec\n",
      "New best model found at epoch 627, saving checkpoint...\n",
      "Epoch 628 | Train Loss: 0.0019 | Test Loss: 0.0017 | LR: 0.001000 | Time: 0.06 sec\n",
      "New best model found at epoch 628, saving checkpoint...\n",
      "Epoch 629 | Train Loss: 0.0019 | Test Loss: 0.0017 | LR: 0.001000 | Time: 0.06 sec\n",
      "New best model found at epoch 629, saving checkpoint...\n",
      "Epoch 630 | Train Loss: 0.0019 | Test Loss: 0.0017 | LR: 0.001000 | Time: 0.06 sec\n",
      "Epoch 631 | Train Loss: 0.0018 | Test Loss: 0.0017 | LR: 0.001000 | Time: 0.06 sec\n",
      "New best model found at epoch 631, saving checkpoint...\n",
      "Epoch 632 | Train Loss: 0.0018 | Test Loss: 0.0017 | LR: 0.001000 | Time: 0.06 sec\n",
      "New best model found at epoch 632, saving checkpoint...\n",
      "Epoch 633 | Train Loss: 0.0018 | Test Loss: 0.0017 | LR: 0.001000 | Time: 0.06 sec\n",
      "New best model found at epoch 633, saving checkpoint...\n",
      "Epoch 634 | Train Loss: 0.0018 | Test Loss: 0.0017 | LR: 0.001000 | Time: 0.06 sec\n",
      "New best model found at epoch 634, saving checkpoint...\n",
      "Epoch 635 | Train Loss: 0.0018 | Test Loss: 0.0017 | LR: 0.001000 | Time: 0.06 sec\n",
      "Epoch 636 | Train Loss: 0.0018 | Test Loss: 0.0016 | LR: 0.001000 | Time: 0.06 sec\n",
      "New best model found at epoch 636, saving checkpoint...\n",
      "Epoch 637 | Train Loss: 0.0018 | Test Loss: 0.0016 | LR: 0.001000 | Time: 0.06 sec\n",
      "Epoch 638 | Train Loss: 0.0019 | Test Loss: 0.0016 | LR: 0.001000 | Time: 0.06 sec\n",
      "New best model found at epoch 638, saving checkpoint...\n",
      "Epoch 639 | Train Loss: 0.0018 | Test Loss: 0.0016 | LR: 0.001000 | Time: 0.05 sec\n",
      "New best model found at epoch 639, saving checkpoint...\n",
      "Epoch 640 | Train Loss: 0.0018 | Test Loss: 0.0016 | LR: 0.001000 | Time: 0.06 sec\n",
      "New best model found at epoch 640, saving checkpoint...\n",
      "Epoch 641 | Train Loss: 0.0018 | Test Loss: 0.0016 | LR: 0.001000 | Time: 0.06 sec\n",
      "New best model found at epoch 641, saving checkpoint...\n",
      "Epoch 642 | Train Loss: 0.0018 | Test Loss: 0.0016 | LR: 0.001000 | Time: 0.06 sec\n",
      "New best model found at epoch 642, saving checkpoint...\n",
      "Epoch 643 | Train Loss: 0.0018 | Test Loss: 0.0016 | LR: 0.001000 | Time: 0.07 sec\n",
      "New best model found at epoch 643, saving checkpoint...\n",
      "Epoch 644 | Train Loss: 0.0018 | Test Loss: 0.0016 | LR: 0.001000 | Time: 0.06 sec\n",
      "New best model found at epoch 644, saving checkpoint...\n",
      "Epoch 645 | Train Loss: 0.0018 | Test Loss: 0.0016 | LR: 0.001000 | Time: 0.07 sec\n",
      "Epoch 646 | Train Loss: 0.0018 | Test Loss: 0.0016 | LR: 0.001000 | Time: 0.06 sec\n",
      "New best model found at epoch 646, saving checkpoint...\n",
      "Epoch 647 | Train Loss: 0.0017 | Test Loss: 0.0016 | LR: 0.001000 | Time: 0.06 sec\n",
      "New best model found at epoch 647, saving checkpoint...\n",
      "Epoch 648 | Train Loss: 0.0018 | Test Loss: 0.0016 | LR: 0.001000 | Time: 0.06 sec\n",
      "New best model found at epoch 648, saving checkpoint...\n",
      "Epoch 649 | Train Loss: 0.0018 | Test Loss: 0.0016 | LR: 0.001000 | Time: 0.06 sec\n",
      "New best model found at epoch 649, saving checkpoint...\n",
      "Epoch 650 | Train Loss: 0.0017 | Test Loss: 0.0016 | LR: 0.001000 | Time: 0.06 sec\n",
      "New best model found at epoch 650, saving checkpoint...\n",
      "Epoch 651 | Train Loss: 0.0017 | Test Loss: 0.0016 | LR: 0.001000 | Time: 0.06 sec\n",
      "New best model found at epoch 651, saving checkpoint...\n",
      "Epoch 652 | Train Loss: 0.0018 | Test Loss: 0.0016 | LR: 0.001000 | Time: 0.06 sec\n",
      "Epoch 653 | Train Loss: 0.0017 | Test Loss: 0.0016 | LR: 0.001000 | Time: 0.06 sec\n",
      "New best model found at epoch 653, saving checkpoint...\n",
      "Epoch 654 | Train Loss: 0.0017 | Test Loss: 0.0016 | LR: 0.001000 | Time: 0.06 sec\n",
      "New best model found at epoch 654, saving checkpoint...\n",
      "Epoch 655 | Train Loss: 0.0017 | Test Loss: 0.0016 | LR: 0.001000 | Time: 0.06 sec\n",
      "Epoch 656 | Train Loss: 0.0017 | Test Loss: 0.0016 | LR: 0.001000 | Time: 0.06 sec\n",
      "New best model found at epoch 656, saving checkpoint...\n",
      "Epoch 657 | Train Loss: 0.0017 | Test Loss: 0.0015 | LR: 0.001000 | Time: 0.06 sec\n",
      "New best model found at epoch 657, saving checkpoint...\n",
      "Epoch 658 | Train Loss: 0.0017 | Test Loss: 0.0015 | LR: 0.001000 | Time: 0.06 sec\n",
      "New best model found at epoch 658, saving checkpoint...\n",
      "Epoch 659 | Train Loss: 0.0017 | Test Loss: 0.0015 | LR: 0.001000 | Time: 0.06 sec\n",
      "New best model found at epoch 659, saving checkpoint...\n",
      "Epoch 660 | Train Loss: 0.0017 | Test Loss: 0.0015 | LR: 0.001000 | Time: 0.06 sec\n",
      "New best model found at epoch 660, saving checkpoint...\n",
      "Epoch 661 | Train Loss: 0.0017 | Test Loss: 0.0015 | LR: 0.001000 | Time: 0.06 sec\n",
      "New best model found at epoch 661, saving checkpoint...\n",
      "Epoch 662 | Train Loss: 0.0017 | Test Loss: 0.0015 | LR: 0.001000 | Time: 0.06 sec\n",
      "New best model found at epoch 662, saving checkpoint...\n",
      "Epoch 663 | Train Loss: 0.0017 | Test Loss: 0.0015 | LR: 0.001000 | Time: 0.06 sec\n",
      "New best model found at epoch 663, saving checkpoint...\n",
      "Epoch 664 | Train Loss: 0.0017 | Test Loss: 0.0015 | LR: 0.001000 | Time: 0.06 sec\n",
      "New best model found at epoch 664, saving checkpoint...\n",
      "Epoch 665 | Train Loss: 0.0017 | Test Loss: 0.0015 | LR: 0.001000 | Time: 0.06 sec\n",
      "New best model found at epoch 665, saving checkpoint...\n",
      "Epoch 666 | Train Loss: 0.0017 | Test Loss: 0.0015 | LR: 0.001000 | Time: 0.06 sec\n",
      "Epoch 667 | Train Loss: 0.0016 | Test Loss: 0.0015 | LR: 0.001000 | Time: 0.07 sec\n",
      "New best model found at epoch 667, saving checkpoint...\n",
      "Epoch 668 | Train Loss: 0.0017 | Test Loss: 0.0015 | LR: 0.001000 | Time: 0.06 sec\n",
      "New best model found at epoch 668, saving checkpoint...\n",
      "Epoch 669 | Train Loss: 0.0016 | Test Loss: 0.0015 | LR: 0.001000 | Time: 0.06 sec\n",
      "Epoch 670 | Train Loss: 0.0016 | Test Loss: 0.0015 | LR: 0.001000 | Time: 0.06 sec\n",
      "New best model found at epoch 670, saving checkpoint...\n",
      "Epoch 671 | Train Loss: 0.0016 | Test Loss: 0.0015 | LR: 0.001000 | Time: 0.06 sec\n",
      "New best model found at epoch 671, saving checkpoint...\n",
      "Epoch 672 | Train Loss: 0.0016 | Test Loss: 0.0015 | LR: 0.001000 | Time: 0.06 sec\n",
      "Epoch 673 | Train Loss: 0.0016 | Test Loss: 0.0015 | LR: 0.001000 | Time: 0.06 sec\n",
      "New best model found at epoch 673, saving checkpoint...\n",
      "Epoch 674 | Train Loss: 0.0016 | Test Loss: 0.0015 | LR: 0.001000 | Time: 0.06 sec\n",
      "New best model found at epoch 674, saving checkpoint...\n",
      "Epoch 675 | Train Loss: 0.0016 | Test Loss: 0.0015 | LR: 0.001000 | Time: 0.06 sec\n",
      "New best model found at epoch 675, saving checkpoint...\n",
      "Epoch 676 | Train Loss: 0.0016 | Test Loss: 0.0015 | LR: 0.001000 | Time: 0.06 sec\n",
      "New best model found at epoch 676, saving checkpoint...\n",
      "Epoch 677 | Train Loss: 0.0016 | Test Loss: 0.0014 | LR: 0.001000 | Time: 0.06 sec\n",
      "New best model found at epoch 677, saving checkpoint...\n",
      "Epoch 678 | Train Loss: 0.0016 | Test Loss: 0.0014 | LR: 0.001000 | Time: 0.06 sec\n",
      "Epoch 679 | Train Loss: 0.0016 | Test Loss: 0.0014 | LR: 0.001000 | Time: 0.07 sec\n",
      "New best model found at epoch 679, saving checkpoint...\n",
      "Epoch 680 | Train Loss: 0.0016 | Test Loss: 0.0014 | LR: 0.001000 | Time: 0.07 sec\n",
      "New best model found at epoch 680, saving checkpoint...\n",
      "Epoch 681 | Train Loss: 0.0016 | Test Loss: 0.0014 | LR: 0.001000 | Time: 0.06 sec\n",
      "New best model found at epoch 681, saving checkpoint...\n",
      "Epoch 682 | Train Loss: 0.0016 | Test Loss: 0.0014 | LR: 0.001000 | Time: 0.06 sec\n",
      "New best model found at epoch 682, saving checkpoint...\n",
      "Epoch 683 | Train Loss: 0.0015 | Test Loss: 0.0014 | LR: 0.001000 | Time: 0.07 sec\n",
      "Epoch 684 | Train Loss: 0.0015 | Test Loss: 0.0014 | LR: 0.001000 | Time: 0.06 sec\n",
      "New best model found at epoch 684, saving checkpoint...\n",
      "Epoch 685 | Train Loss: 0.0015 | Test Loss: 0.0014 | LR: 0.001000 | Time: 0.06 sec\n",
      "New best model found at epoch 685, saving checkpoint...\n",
      "Epoch 686 | Train Loss: 0.0015 | Test Loss: 0.0014 | LR: 0.001000 | Time: 0.06 sec\n",
      "New best model found at epoch 686, saving checkpoint...\n",
      "Epoch 687 | Train Loss: 0.0015 | Test Loss: 0.0014 | LR: 0.001000 | Time: 0.06 sec\n",
      "New best model found at epoch 687, saving checkpoint...\n",
      "Epoch 688 | Train Loss: 0.0015 | Test Loss: 0.0014 | LR: 0.001000 | Time: 0.06 sec\n",
      "Epoch 689 | Train Loss: 0.0015 | Test Loss: 0.0014 | LR: 0.001000 | Time: 0.06 sec\n",
      "New best model found at epoch 689, saving checkpoint...\n",
      "Epoch 690 | Train Loss: 0.0015 | Test Loss: 0.0014 | LR: 0.001000 | Time: 0.06 sec\n",
      "New best model found at epoch 690, saving checkpoint...\n",
      "Epoch 691 | Train Loss: 0.0015 | Test Loss: 0.0014 | LR: 0.001000 | Time: 0.06 sec\n",
      "New best model found at epoch 691, saving checkpoint...\n",
      "Epoch 692 | Train Loss: 0.0015 | Test Loss: 0.0014 | LR: 0.001000 | Time: 0.06 sec\n",
      "New best model found at epoch 692, saving checkpoint...\n",
      "Epoch 693 | Train Loss: 0.0015 | Test Loss: 0.0014 | LR: 0.001000 | Time: 0.07 sec\n",
      "New best model found at epoch 693, saving checkpoint...\n",
      "Epoch 694 | Train Loss: 0.0015 | Test Loss: 0.0014 | LR: 0.001000 | Time: 0.06 sec\n",
      "New best model found at epoch 694, saving checkpoint...\n",
      "Epoch 695 | Train Loss: 0.0015 | Test Loss: 0.0014 | LR: 0.001000 | Time: 0.06 sec\n",
      "New best model found at epoch 695, saving checkpoint...\n",
      "Epoch 696 | Train Loss: 0.0015 | Test Loss: 0.0014 | LR: 0.001000 | Time: 0.06 sec\n",
      "New best model found at epoch 696, saving checkpoint...\n",
      "Epoch 697 | Train Loss: 0.0014 | Test Loss: 0.0014 | LR: 0.001000 | Time: 0.06 sec\n",
      "New best model found at epoch 697, saving checkpoint...\n",
      "Epoch 698 | Train Loss: 0.0014 | Test Loss: 0.0013 | LR: 0.001000 | Time: 0.07 sec\n",
      "New best model found at epoch 698, saving checkpoint...\n",
      "Epoch 699 | Train Loss: 0.0015 | Test Loss: 0.0013 | LR: 0.001000 | Time: 0.06 sec\n",
      "New best model found at epoch 699, saving checkpoint...\n",
      "Epoch 700 | Train Loss: 0.0015 | Test Loss: 0.0013 | LR: 0.001000 | Time: 0.06 sec\n",
      "New best model found at epoch 700, saving checkpoint...\n",
      "Epoch 701 | Train Loss: 0.0014 | Test Loss: 0.0013 | LR: 0.001000 | Time: 0.07 sec\n",
      "New best model found at epoch 701, saving checkpoint...\n",
      "Epoch 702 | Train Loss: 0.0014 | Test Loss: 0.0013 | LR: 0.001000 | Time: 0.06 sec\n",
      "New best model found at epoch 702, saving checkpoint...\n",
      "Epoch 703 | Train Loss: 0.0014 | Test Loss: 0.0013 | LR: 0.001000 | Time: 0.07 sec\n",
      "New best model found at epoch 703, saving checkpoint...\n",
      "Epoch 704 | Train Loss: 0.0014 | Test Loss: 0.0013 | LR: 0.001000 | Time: 0.06 sec\n",
      "New best model found at epoch 704, saving checkpoint...\n",
      "Epoch 705 | Train Loss: 0.0014 | Test Loss: 0.0013 | LR: 0.001000 | Time: 0.07 sec\n",
      "New best model found at epoch 705, saving checkpoint...\n",
      "Epoch 706 | Train Loss: 0.0014 | Test Loss: 0.0013 | LR: 0.001000 | Time: 0.06 sec\n",
      "New best model found at epoch 706, saving checkpoint...\n",
      "Epoch 707 | Train Loss: 0.0014 | Test Loss: 0.0013 | LR: 0.001000 | Time: 0.06 sec\n",
      "New best model found at epoch 707, saving checkpoint...\n",
      "Epoch 708 | Train Loss: 0.0014 | Test Loss: 0.0013 | LR: 0.001000 | Time: 0.06 sec\n",
      "New best model found at epoch 708, saving checkpoint...\n",
      "Epoch 709 | Train Loss: 0.0014 | Test Loss: 0.0013 | LR: 0.001000 | Time: 0.07 sec\n",
      "New best model found at epoch 709, saving checkpoint...\n",
      "Epoch 710 | Train Loss: 0.0013 | Test Loss: 0.0013 | LR: 0.001000 | Time: 0.06 sec\n",
      "New best model found at epoch 710, saving checkpoint...\n",
      "Epoch 711 | Train Loss: 0.0014 | Test Loss: 0.0013 | LR: 0.001000 | Time: 0.06 sec\n",
      "New best model found at epoch 711, saving checkpoint...\n",
      "Epoch 712 | Train Loss: 0.0014 | Test Loss: 0.0013 | LR: 0.001000 | Time: 0.06 sec\n",
      "New best model found at epoch 712, saving checkpoint...\n",
      "Epoch 713 | Train Loss: 0.0013 | Test Loss: 0.0013 | LR: 0.001000 | Time: 0.07 sec\n",
      "New best model found at epoch 713, saving checkpoint...\n",
      "Epoch 714 | Train Loss: 0.0013 | Test Loss: 0.0013 | LR: 0.001000 | Time: 0.06 sec\n",
      "Epoch 715 | Train Loss: 0.0013 | Test Loss: 0.0013 | LR: 0.001000 | Time: 0.06 sec\n",
      "Epoch 716 | Train Loss: 0.0013 | Test Loss: 0.0013 | LR: 0.001000 | Time: 0.07 sec\n",
      "New best model found at epoch 716, saving checkpoint...\n",
      "Epoch 717 | Train Loss: 0.0013 | Test Loss: 0.0013 | LR: 0.001000 | Time: 0.06 sec\n",
      "New best model found at epoch 717, saving checkpoint...\n",
      "Epoch 718 | Train Loss: 0.0013 | Test Loss: 0.0013 | LR: 0.001000 | Time: 0.07 sec\n",
      "Epoch 719 | Train Loss: 0.0013 | Test Loss: 0.0013 | LR: 0.001000 | Time: 0.07 sec\n",
      "New best model found at epoch 719, saving checkpoint...\n",
      "Epoch 720 | Train Loss: 0.0013 | Test Loss: 0.0012 | LR: 0.001000 | Time: 0.06 sec\n",
      "New best model found at epoch 720, saving checkpoint...\n",
      "Epoch 721 | Train Loss: 0.0013 | Test Loss: 0.0012 | LR: 0.001000 | Time: 0.07 sec\n",
      "New best model found at epoch 721, saving checkpoint...\n",
      "Epoch 722 | Train Loss: 0.0013 | Test Loss: 0.0012 | LR: 0.001000 | Time: 0.06 sec\n",
      "New best model found at epoch 722, saving checkpoint...\n",
      "Epoch 723 | Train Loss: 0.0013 | Test Loss: 0.0012 | LR: 0.001000 | Time: 0.06 sec\n",
      "New best model found at epoch 723, saving checkpoint...\n",
      "Epoch 724 | Train Loss: 0.0013 | Test Loss: 0.0012 | LR: 0.001000 | Time: 0.07 sec\n",
      "New best model found at epoch 724, saving checkpoint...\n",
      "Epoch 725 | Train Loss: 0.0013 | Test Loss: 0.0012 | LR: 0.001000 | Time: 0.07 sec\n",
      "Epoch 726 | Train Loss: 0.0013 | Test Loss: 0.0012 | LR: 0.001000 | Time: 0.07 sec\n",
      "Epoch 727 | Train Loss: 0.0012 | Test Loss: 0.0012 | LR: 0.001000 | Time: 0.07 sec\n",
      "New best model found at epoch 727, saving checkpoint...\n",
      "Epoch 728 | Train Loss: 0.0012 | Test Loss: 0.0012 | LR: 0.001000 | Time: 0.07 sec\n",
      "New best model found at epoch 728, saving checkpoint...\n",
      "Epoch 729 | Train Loss: 0.0012 | Test Loss: 0.0012 | LR: 0.001000 | Time: 0.08 sec\n",
      "New best model found at epoch 729, saving checkpoint...\n",
      "Epoch 730 | Train Loss: 0.0012 | Test Loss: 0.0012 | LR: 0.001000 | Time: 0.06 sec\n",
      "New best model found at epoch 730, saving checkpoint...\n",
      "Epoch 731 | Train Loss: 0.0012 | Test Loss: 0.0012 | LR: 0.001000 | Time: 0.07 sec\n",
      "New best model found at epoch 731, saving checkpoint...\n",
      "Epoch 732 | Train Loss: 0.0012 | Test Loss: 0.0012 | LR: 0.001000 | Time: 0.07 sec\n",
      "New best model found at epoch 732, saving checkpoint...\n",
      "Epoch 733 | Train Loss: 0.0012 | Test Loss: 0.0012 | LR: 0.001000 | Time: 0.07 sec\n",
      "New best model found at epoch 733, saving checkpoint...\n",
      "Epoch 734 | Train Loss: 0.0012 | Test Loss: 0.0012 | LR: 0.001000 | Time: 0.06 sec\n",
      "New best model found at epoch 734, saving checkpoint...\n",
      "Epoch 735 | Train Loss: 0.0012 | Test Loss: 0.0012 | LR: 0.001000 | Time: 0.07 sec\n",
      "New best model found at epoch 735, saving checkpoint...\n",
      "Epoch 736 | Train Loss: 0.0012 | Test Loss: 0.0012 | LR: 0.001000 | Time: 0.07 sec\n",
      "Epoch 737 | Train Loss: 0.0012 | Test Loss: 0.0012 | LR: 0.001000 | Time: 0.07 sec\n",
      "New best model found at epoch 737, saving checkpoint...\n",
      "Epoch 738 | Train Loss: 0.0012 | Test Loss: 0.0012 | LR: 0.001000 | Time: 0.06 sec\n",
      "New best model found at epoch 738, saving checkpoint...\n",
      "Epoch 739 | Train Loss: 0.0012 | Test Loss: 0.0012 | LR: 0.001000 | Time: 0.07 sec\n",
      "New best model found at epoch 739, saving checkpoint...\n",
      "Epoch 740 | Train Loss: 0.0012 | Test Loss: 0.0011 | LR: 0.001000 | Time: 0.07 sec\n",
      "New best model found at epoch 740, saving checkpoint...\n",
      "Epoch 741 | Train Loss: 0.0011 | Test Loss: 0.0011 | LR: 0.001000 | Time: 0.07 sec\n",
      "New best model found at epoch 741, saving checkpoint...\n",
      "Epoch 742 | Train Loss: 0.0012 | Test Loss: 0.0011 | LR: 0.001000 | Time: 0.07 sec\n",
      "New best model found at epoch 742, saving checkpoint...\n",
      "Epoch 743 | Train Loss: 0.0011 | Test Loss: 0.0011 | LR: 0.001000 | Time: 0.07 sec\n",
      "New best model found at epoch 743, saving checkpoint...\n",
      "Epoch 744 | Train Loss: 0.0011 | Test Loss: 0.0011 | LR: 0.001000 | Time: 0.08 sec\n",
      "New best model found at epoch 744, saving checkpoint...\n",
      "Epoch 745 | Train Loss: 0.0011 | Test Loss: 0.0011 | LR: 0.001000 | Time: 0.07 sec\n",
      "New best model found at epoch 745, saving checkpoint...\n",
      "Epoch 746 | Train Loss: 0.0011 | Test Loss: 0.0011 | LR: 0.001000 | Time: 0.08 sec\n",
      "New best model found at epoch 746, saving checkpoint...\n",
      "Epoch 747 | Train Loss: 0.0011 | Test Loss: 0.0011 | LR: 0.001000 | Time: 0.08 sec\n",
      "New best model found at epoch 747, saving checkpoint...\n",
      "Epoch 748 | Train Loss: 0.0011 | Test Loss: 0.0011 | LR: 0.001000 | Time: 0.08 sec\n",
      "Epoch 749 | Train Loss: 0.0011 | Test Loss: 0.0011 | LR: 0.001000 | Time: 0.08 sec\n",
      "New best model found at epoch 749, saving checkpoint...\n",
      "Epoch 750 | Train Loss: 0.0011 | Test Loss: 0.0011 | LR: 0.001000 | Time: 0.07 sec\n",
      "New best model found at epoch 750, saving checkpoint...\n",
      "Epoch 751 | Train Loss: 0.0011 | Test Loss: 0.0011 | LR: 0.001000 | Time: 0.08 sec\n",
      "New best model found at epoch 751, saving checkpoint...\n",
      "Epoch 752 | Train Loss: 0.0011 | Test Loss: 0.0011 | LR: 0.001000 | Time: 0.08 sec\n",
      "New best model found at epoch 752, saving checkpoint...\n",
      "Epoch 753 | Train Loss: 0.0011 | Test Loss: 0.0011 | LR: 0.001000 | Time: 0.07 sec\n",
      "New best model found at epoch 753, saving checkpoint...\n",
      "Epoch 754 | Train Loss: 0.0011 | Test Loss: 0.0011 | LR: 0.001000 | Time: 0.07 sec\n",
      "New best model found at epoch 754, saving checkpoint...\n",
      "Epoch 755 | Train Loss: 0.0011 | Test Loss: 0.0011 | LR: 0.001000 | Time: 0.07 sec\n",
      "New best model found at epoch 755, saving checkpoint...\n",
      "Epoch 756 | Train Loss: 0.0010 | Test Loss: 0.0011 | LR: 0.001000 | Time: 0.07 sec\n",
      "New best model found at epoch 756, saving checkpoint...\n",
      "Epoch 757 | Train Loss: 0.0010 | Test Loss: 0.0011 | LR: 0.001000 | Time: 0.08 sec\n",
      "New best model found at epoch 757, saving checkpoint...\n",
      "Epoch 758 | Train Loss: 0.0010 | Test Loss: 0.0011 | LR: 0.001000 | Time: 0.07 sec\n",
      "New best model found at epoch 758, saving checkpoint...\n",
      "Epoch 759 | Train Loss: 0.0010 | Test Loss: 0.0011 | LR: 0.001000 | Time: 0.07 sec\n",
      "New best model found at epoch 759, saving checkpoint...\n",
      "Epoch 760 | Train Loss: 0.0010 | Test Loss: 0.0010 | LR: 0.001000 | Time: 0.07 sec\n",
      "New best model found at epoch 760, saving checkpoint...\n",
      "Epoch 761 | Train Loss: 0.0010 | Test Loss: 0.0010 | LR: 0.001000 | Time: 0.07 sec\n",
      "New best model found at epoch 761, saving checkpoint...\n",
      "Epoch 762 | Train Loss: 0.0010 | Test Loss: 0.0010 | LR: 0.001000 | Time: 0.07 sec\n",
      "New best model found at epoch 762, saving checkpoint...\n",
      "Epoch 763 | Train Loss: 0.0010 | Test Loss: 0.0010 | LR: 0.001000 | Time: 0.07 sec\n",
      "New best model found at epoch 763, saving checkpoint...\n",
      "Epoch 764 | Train Loss: 0.0010 | Test Loss: 0.0010 | LR: 0.001000 | Time: 0.07 sec\n",
      "New best model found at epoch 764, saving checkpoint...\n",
      "Epoch 765 | Train Loss: 0.0010 | Test Loss: 0.0010 | LR: 0.001000 | Time: 0.07 sec\n",
      "Epoch 766 | Train Loss: 0.0010 | Test Loss: 0.0010 | LR: 0.001000 | Time: 0.07 sec\n",
      "New best model found at epoch 766, saving checkpoint...\n",
      "Epoch 767 | Train Loss: 0.0010 | Test Loss: 0.0010 | LR: 0.001000 | Time: 0.07 sec\n",
      "New best model found at epoch 767, saving checkpoint...\n",
      "Epoch 768 | Train Loss: 0.0010 | Test Loss: 0.0010 | LR: 0.001000 | Time: 0.07 sec\n",
      "New best model found at epoch 768, saving checkpoint...\n",
      "Epoch 769 | Train Loss: 0.0010 | Test Loss: 0.0010 | LR: 0.001000 | Time: 0.07 sec\n",
      "New best model found at epoch 769, saving checkpoint...\n",
      "Epoch 770 | Train Loss: 0.0009 | Test Loss: 0.0010 | LR: 0.001000 | Time: 0.07 sec\n",
      "New best model found at epoch 770, saving checkpoint...\n",
      "Epoch 771 | Train Loss: 0.0010 | Test Loss: 0.0010 | LR: 0.001000 | Time: 0.07 sec\n",
      "New best model found at epoch 771, saving checkpoint...\n",
      "Epoch 772 | Train Loss: 0.0010 | Test Loss: 0.0010 | LR: 0.001000 | Time: 0.07 sec\n",
      "Epoch 773 | Train Loss: 0.0009 | Test Loss: 0.0010 | LR: 0.001000 | Time: 0.07 sec\n",
      "New best model found at epoch 773, saving checkpoint...\n",
      "Epoch 774 | Train Loss: 0.0009 | Test Loss: 0.0010 | LR: 0.001000 | Time: 0.07 sec\n",
      "New best model found at epoch 774, saving checkpoint...\n",
      "Epoch 775 | Train Loss: 0.0009 | Test Loss: 0.0010 | LR: 0.001000 | Time: 0.07 sec\n",
      "New best model found at epoch 775, saving checkpoint...\n",
      "Epoch 776 | Train Loss: 0.0009 | Test Loss: 0.0010 | LR: 0.001000 | Time: 0.07 sec\n",
      "New best model found at epoch 776, saving checkpoint...\n",
      "Epoch 777 | Train Loss: 0.0009 | Test Loss: 0.0010 | LR: 0.001000 | Time: 0.07 sec\n",
      "New best model found at epoch 777, saving checkpoint...\n",
      "Epoch 778 | Train Loss: 0.0009 | Test Loss: 0.0010 | LR: 0.001000 | Time: 0.07 sec\n",
      "New best model found at epoch 778, saving checkpoint...\n",
      "Epoch 779 | Train Loss: 0.0009 | Test Loss: 0.0010 | LR: 0.001000 | Time: 0.07 sec\n",
      "New best model found at epoch 779, saving checkpoint...\n",
      "Epoch 780 | Train Loss: 0.0009 | Test Loss: 0.0010 | LR: 0.001000 | Time: 0.07 sec\n",
      "New best model found at epoch 780, saving checkpoint...\n",
      "Epoch 781 | Train Loss: 0.0009 | Test Loss: 0.0010 | LR: 0.001000 | Time: 0.07 sec\n",
      "New best model found at epoch 781, saving checkpoint...\n",
      "Epoch 782 | Train Loss: 0.0009 | Test Loss: 0.0010 | LR: 0.001000 | Time: 0.07 sec\n",
      "New best model found at epoch 782, saving checkpoint...\n",
      "Epoch 783 | Train Loss: 0.0009 | Test Loss: 0.0009 | LR: 0.001000 | Time: 0.07 sec\n",
      "New best model found at epoch 783, saving checkpoint...\n",
      "Epoch 784 | Train Loss: 0.0009 | Test Loss: 0.0009 | LR: 0.001000 | Time: 0.07 sec\n",
      "New best model found at epoch 784, saving checkpoint...\n",
      "Epoch 785 | Train Loss: 0.0009 | Test Loss: 0.0009 | LR: 0.001000 | Time: 0.07 sec\n",
      "New best model found at epoch 785, saving checkpoint...\n",
      "Epoch 786 | Train Loss: 0.0009 | Test Loss: 0.0009 | LR: 0.001000 | Time: 0.07 sec\n",
      "New best model found at epoch 786, saving checkpoint...\n",
      "Epoch 787 | Train Loss: 0.0009 | Test Loss: 0.0009 | LR: 0.001000 | Time: 0.07 sec\n",
      "New best model found at epoch 787, saving checkpoint...\n",
      "Epoch 788 | Train Loss: 0.0009 | Test Loss: 0.0009 | LR: 0.001000 | Time: 0.07 sec\n",
      "New best model found at epoch 788, saving checkpoint...\n",
      "Epoch 789 | Train Loss: 0.0009 | Test Loss: 0.0009 | LR: 0.001000 | Time: 0.07 sec\n",
      "Epoch 790 | Train Loss: 0.0008 | Test Loss: 0.0009 | LR: 0.001000 | Time: 0.07 sec\n",
      "New best model found at epoch 790, saving checkpoint...\n",
      "Epoch 791 | Train Loss: 0.0008 | Test Loss: 0.0009 | LR: 0.001000 | Time: 0.07 sec\n",
      "New best model found at epoch 791, saving checkpoint...\n",
      "Epoch 792 | Train Loss: 0.0008 | Test Loss: 0.0009 | LR: 0.001000 | Time: 0.08 sec\n",
      "New best model found at epoch 792, saving checkpoint...\n",
      "Epoch 793 | Train Loss: 0.0008 | Test Loss: 0.0009 | LR: 0.001000 | Time: 0.07 sec\n",
      "New best model found at epoch 793, saving checkpoint...\n",
      "Epoch 794 | Train Loss: 0.0008 | Test Loss: 0.0009 | LR: 0.001000 | Time: 0.08 sec\n",
      "New best model found at epoch 794, saving checkpoint...\n",
      "Epoch 795 | Train Loss: 0.0008 | Test Loss: 0.0009 | LR: 0.001000 | Time: 0.07 sec\n",
      "New best model found at epoch 795, saving checkpoint...\n",
      "Epoch 796 | Train Loss: 0.0008 | Test Loss: 0.0009 | LR: 0.001000 | Time: 0.07 sec\n",
      "New best model found at epoch 796, saving checkpoint...\n",
      "Epoch 797 | Train Loss: 0.0008 | Test Loss: 0.0009 | LR: 0.001000 | Time: 0.07 sec\n",
      "New best model found at epoch 797, saving checkpoint...\n",
      "Epoch 798 | Train Loss: 0.0008 | Test Loss: 0.0009 | LR: 0.001000 | Time: 0.07 sec\n",
      "New best model found at epoch 798, saving checkpoint...\n",
      "Epoch 799 | Train Loss: 0.0008 | Test Loss: 0.0009 | LR: 0.001000 | Time: 0.07 sec\n",
      "New best model found at epoch 799, saving checkpoint...\n",
      "Epoch 800 | Train Loss: 0.0008 | Test Loss: 0.0009 | LR: 0.001000 | Time: 0.07 sec\n",
      "New best model found at epoch 800, saving checkpoint...\n",
      "Epoch 801 | Train Loss: 0.0008 | Test Loss: 0.0009 | LR: 0.001000 | Time: 0.07 sec\n",
      "New best model found at epoch 801, saving checkpoint...\n",
      "Epoch 802 | Train Loss: 0.0008 | Test Loss: 0.0009 | LR: 0.001000 | Time: 0.07 sec\n",
      "New best model found at epoch 802, saving checkpoint...\n",
      "Epoch 803 | Train Loss: 0.0008 | Test Loss: 0.0009 | LR: 0.001000 | Time: 0.07 sec\n",
      "New best model found at epoch 803, saving checkpoint...\n",
      "Epoch 804 | Train Loss: 0.0008 | Test Loss: 0.0009 | LR: 0.001000 | Time: 0.07 sec\n",
      "New best model found at epoch 804, saving checkpoint...\n",
      "Epoch 805 | Train Loss: 0.0008 | Test Loss: 0.0009 | LR: 0.001000 | Time: 0.07 sec\n",
      "New best model found at epoch 805, saving checkpoint...\n",
      "Epoch 806 | Train Loss: 0.0008 | Test Loss: 0.0008 | LR: 0.001000 | Time: 0.07 sec\n",
      "New best model found at epoch 806, saving checkpoint...\n",
      "Epoch 807 | Train Loss: 0.0008 | Test Loss: 0.0008 | LR: 0.001000 | Time: 0.07 sec\n",
      "New best model found at epoch 807, saving checkpoint...\n",
      "Epoch 808 | Train Loss: 0.0008 | Test Loss: 0.0008 | LR: 0.001000 | Time: 0.07 sec\n",
      "New best model found at epoch 808, saving checkpoint...\n",
      "Epoch 809 | Train Loss: 0.0008 | Test Loss: 0.0008 | LR: 0.001000 | Time: 0.08 sec\n",
      "New best model found at epoch 809, saving checkpoint...\n",
      "Epoch 810 | Train Loss: 0.0008 | Test Loss: 0.0008 | LR: 0.001000 | Time: 0.07 sec\n",
      "New best model found at epoch 810, saving checkpoint...\n",
      "Epoch 811 | Train Loss: 0.0007 | Test Loss: 0.0008 | LR: 0.001000 | Time: 0.07 sec\n",
      "New best model found at epoch 811, saving checkpoint...\n",
      "Epoch 812 | Train Loss: 0.0007 | Test Loss: 0.0008 | LR: 0.001000 | Time: 0.08 sec\n",
      "New best model found at epoch 812, saving checkpoint...\n",
      "Epoch 813 | Train Loss: 0.0007 | Test Loss: 0.0008 | LR: 0.001000 | Time: 0.07 sec\n",
      "New best model found at epoch 813, saving checkpoint...\n",
      "Epoch 814 | Train Loss: 0.0007 | Test Loss: 0.0008 | LR: 0.001000 | Time: 0.08 sec\n",
      "Epoch 815 | Train Loss: 0.0007 | Test Loss: 0.0008 | LR: 0.001000 | Time: 0.09 sec\n",
      "New best model found at epoch 815, saving checkpoint...\n",
      "Epoch 816 | Train Loss: 0.0007 | Test Loss: 0.0008 | LR: 0.001000 | Time: 0.10 sec\n",
      "New best model found at epoch 816, saving checkpoint...\n",
      "Epoch 817 | Train Loss: 0.0007 | Test Loss: 0.0008 | LR: 0.001000 | Time: 0.10 sec\n",
      "New best model found at epoch 817, saving checkpoint...\n",
      "Epoch 818 | Train Loss: 0.0007 | Test Loss: 0.0008 | LR: 0.001000 | Time: 0.11 sec\n",
      "New best model found at epoch 818, saving checkpoint...\n",
      "Epoch 819 | Train Loss: 0.0007 | Test Loss: 0.0008 | LR: 0.001000 | Time: 0.10 sec\n",
      "New best model found at epoch 819, saving checkpoint...\n",
      "Epoch 820 | Train Loss: 0.0007 | Test Loss: 0.0008 | LR: 0.001000 | Time: 0.10 sec\n",
      "New best model found at epoch 820, saving checkpoint...\n",
      "Epoch 821 | Train Loss: 0.0007 | Test Loss: 0.0008 | LR: 0.001000 | Time: 0.11 sec\n",
      "New best model found at epoch 821, saving checkpoint...\n",
      "Epoch 822 | Train Loss: 0.0007 | Test Loss: 0.0008 | LR: 0.001000 | Time: 0.10 sec\n",
      "New best model found at epoch 822, saving checkpoint...\n",
      "Epoch 823 | Train Loss: 0.0007 | Test Loss: 0.0008 | LR: 0.001000 | Time: 0.11 sec\n",
      "New best model found at epoch 823, saving checkpoint...\n",
      "Epoch 824 | Train Loss: 0.0007 | Test Loss: 0.0008 | LR: 0.001000 | Time: 0.11 sec\n",
      "New best model found at epoch 824, saving checkpoint...\n",
      "Epoch 825 | Train Loss: 0.0007 | Test Loss: 0.0008 | LR: 0.001000 | Time: 0.11 sec\n",
      "New best model found at epoch 825, saving checkpoint...\n",
      "Epoch 826 | Train Loss: 0.0007 | Test Loss: 0.0008 | LR: 0.001000 | Time: 0.13 sec\n",
      "New best model found at epoch 826, saving checkpoint...\n",
      "Epoch 827 | Train Loss: 0.0007 | Test Loss: 0.0008 | LR: 0.001000 | Time: 0.13 sec\n",
      "New best model found at epoch 827, saving checkpoint...\n",
      "Epoch 828 | Train Loss: 0.0007 | Test Loss: 0.0008 | LR: 0.001000 | Time: 0.12 sec\n",
      "New best model found at epoch 828, saving checkpoint...\n",
      "Epoch 829 | Train Loss: 0.0006 | Test Loss: 0.0008 | LR: 0.001000 | Time: 0.11 sec\n",
      "New best model found at epoch 829, saving checkpoint...\n",
      "Epoch 830 | Train Loss: 0.0007 | Test Loss: 0.0007 | LR: 0.001000 | Time: 0.11 sec\n",
      "New best model found at epoch 830, saving checkpoint...\n",
      "Epoch 831 | Train Loss: 0.0006 | Test Loss: 0.0007 | LR: 0.001000 | Time: 0.11 sec\n",
      "New best model found at epoch 831, saving checkpoint...\n",
      "Epoch 832 | Train Loss: 0.0007 | Test Loss: 0.0007 | LR: 0.001000 | Time: 0.11 sec\n",
      "New best model found at epoch 832, saving checkpoint...\n",
      "Epoch 833 | Train Loss: 0.0006 | Test Loss: 0.0007 | LR: 0.001000 | Time: 0.11 sec\n",
      "New best model found at epoch 833, saving checkpoint...\n",
      "Epoch 834 | Train Loss: 0.0006 | Test Loss: 0.0007 | LR: 0.001000 | Time: 0.11 sec\n",
      "New best model found at epoch 834, saving checkpoint...\n",
      "Epoch 835 | Train Loss: 0.0006 | Test Loss: 0.0007 | LR: 0.001000 | Time: 0.11 sec\n",
      "New best model found at epoch 835, saving checkpoint...\n",
      "Epoch 836 | Train Loss: 0.0006 | Test Loss: 0.0007 | LR: 0.001000 | Time: 0.13 sec\n",
      "New best model found at epoch 836, saving checkpoint...\n",
      "Epoch 837 | Train Loss: 0.0006 | Test Loss: 0.0007 | LR: 0.001000 | Time: 0.12 sec\n",
      "New best model found at epoch 837, saving checkpoint...\n",
      "Epoch 838 | Train Loss: 0.0006 | Test Loss: 0.0007 | LR: 0.001000 | Time: 0.11 sec\n",
      "Epoch 839 | Train Loss: 0.0006 | Test Loss: 0.0007 | LR: 0.001000 | Time: 0.12 sec\n",
      "Epoch 840 | Train Loss: 0.0006 | Test Loss: 0.0007 | LR: 0.001000 | Time: 0.14 sec\n",
      "New best model found at epoch 840, saving checkpoint...\n",
      "Epoch 841 | Train Loss: 0.0006 | Test Loss: 0.0007 | LR: 0.001000 | Time: 0.14 sec\n",
      "New best model found at epoch 841, saving checkpoint...\n",
      "Epoch 842 | Train Loss: 0.0006 | Test Loss: 0.0007 | LR: 0.001000 | Time: 0.11 sec\n",
      "New best model found at epoch 842, saving checkpoint...\n",
      "Epoch 843 | Train Loss: 0.0006 | Test Loss: 0.0007 | LR: 0.001000 | Time: 0.12 sec\n",
      "New best model found at epoch 843, saving checkpoint...\n",
      "Epoch 844 | Train Loss: 0.0006 | Test Loss: 0.0007 | LR: 0.001000 | Time: 0.10 sec\n",
      "New best model found at epoch 844, saving checkpoint...\n",
      "Epoch 845 | Train Loss: 0.0006 | Test Loss: 0.0007 | LR: 0.001000 | Time: 0.12 sec\n",
      "New best model found at epoch 845, saving checkpoint...\n",
      "Epoch 846 | Train Loss: 0.0006 | Test Loss: 0.0007 | LR: 0.001000 | Time: 0.13 sec\n",
      "New best model found at epoch 846, saving checkpoint...\n",
      "Epoch 847 | Train Loss: 0.0006 | Test Loss: 0.0007 | LR: 0.001000 | Time: 0.14 sec\n",
      "New best model found at epoch 847, saving checkpoint...\n",
      "Epoch 848 | Train Loss: 0.0006 | Test Loss: 0.0007 | LR: 0.001000 | Time: 0.12 sec\n",
      "New best model found at epoch 848, saving checkpoint...\n",
      "Epoch 849 | Train Loss: 0.0006 | Test Loss: 0.0007 | LR: 0.001000 | Time: 0.12 sec\n",
      "New best model found at epoch 849, saving checkpoint...\n",
      "Epoch 850 | Train Loss: 0.0006 | Test Loss: 0.0007 | LR: 0.001000 | Time: 0.12 sec\n",
      "New best model found at epoch 850, saving checkpoint...\n",
      "Epoch 851 | Train Loss: 0.0006 | Test Loss: 0.0007 | LR: 0.001000 | Time: 0.12 sec\n",
      "New best model found at epoch 851, saving checkpoint...\n",
      "Epoch 852 | Train Loss: 0.0006 | Test Loss: 0.0007 | LR: 0.001000 | Time: 0.11 sec\n",
      "New best model found at epoch 852, saving checkpoint...\n",
      "Epoch 853 | Train Loss: 0.0006 | Test Loss: 0.0007 | LR: 0.001000 | Time: 0.11 sec\n",
      "New best model found at epoch 853, saving checkpoint...\n",
      "Epoch 854 | Train Loss: 0.0006 | Test Loss: 0.0007 | LR: 0.001000 | Time: 0.12 sec\n",
      "New best model found at epoch 854, saving checkpoint...\n",
      "Epoch 855 | Train Loss: 0.0006 | Test Loss: 0.0007 | LR: 0.001000 | Time: 0.10 sec\n",
      "New best model found at epoch 855, saving checkpoint...\n",
      "Epoch 856 | Train Loss: 0.0006 | Test Loss: 0.0007 | LR: 0.001000 | Time: 0.11 sec\n",
      "New best model found at epoch 856, saving checkpoint...\n",
      "Epoch 857 | Train Loss: 0.0006 | Test Loss: 0.0007 | LR: 0.001000 | Time: 0.11 sec\n",
      "New best model found at epoch 857, saving checkpoint...\n",
      "Epoch 858 | Train Loss: 0.0006 | Test Loss: 0.0007 | LR: 0.001000 | Time: 0.21 sec\n",
      "New best model found at epoch 858, saving checkpoint...\n",
      "Epoch 859 | Train Loss: 0.0005 | Test Loss: 0.0006 | LR: 0.001000 | Time: 0.13 sec\n",
      "New best model found at epoch 859, saving checkpoint...\n",
      "Epoch 860 | Train Loss: 0.0006 | Test Loss: 0.0006 | LR: 0.001000 | Time: 0.11 sec\n",
      "New best model found at epoch 860, saving checkpoint...\n",
      "Epoch 861 | Train Loss: 0.0005 | Test Loss: 0.0006 | LR: 0.001000 | Time: 0.11 sec\n",
      "New best model found at epoch 861, saving checkpoint...\n",
      "Epoch 862 | Train Loss: 0.0005 | Test Loss: 0.0006 | LR: 0.001000 | Time: 0.12 sec\n",
      "New best model found at epoch 862, saving checkpoint...\n",
      "Epoch 863 | Train Loss: 0.0005 | Test Loss: 0.0006 | LR: 0.001000 | Time: 0.12 sec\n",
      "New best model found at epoch 863, saving checkpoint...\n",
      "Epoch 864 | Train Loss: 0.0005 | Test Loss: 0.0006 | LR: 0.001000 | Time: 0.13 sec\n",
      "New best model found at epoch 864, saving checkpoint...\n",
      "Epoch 865 | Train Loss: 0.0005 | Test Loss: 0.0006 | LR: 0.001000 | Time: 0.13 sec\n",
      "New best model found at epoch 865, saving checkpoint...\n",
      "Epoch 866 | Train Loss: 0.0005 | Test Loss: 0.0006 | LR: 0.001000 | Time: 0.14 sec\n",
      "New best model found at epoch 866, saving checkpoint...\n",
      "Epoch 867 | Train Loss: 0.0005 | Test Loss: 0.0006 | LR: 0.001000 | Time: 0.12 sec\n",
      "New best model found at epoch 867, saving checkpoint...\n",
      "Epoch 868 | Train Loss: 0.0005 | Test Loss: 0.0006 | LR: 0.001000 | Time: 0.16 sec\n",
      "New best model found at epoch 868, saving checkpoint...\n",
      "Epoch 869 | Train Loss: 0.0005 | Test Loss: 0.0006 | LR: 0.001000 | Time: 0.12 sec\n",
      "Epoch 870 | Train Loss: 0.0005 | Test Loss: 0.0006 | LR: 0.001000 | Time: 0.13 sec\n",
      "New best model found at epoch 870, saving checkpoint...\n",
      "Epoch 871 | Train Loss: 0.0005 | Test Loss: 0.0006 | LR: 0.001000 | Time: 0.11 sec\n",
      "New best model found at epoch 871, saving checkpoint...\n",
      "Epoch 872 | Train Loss: 0.0005 | Test Loss: 0.0006 | LR: 0.001000 | Time: 0.12 sec\n",
      "New best model found at epoch 872, saving checkpoint...\n",
      "Epoch 873 | Train Loss: 0.0005 | Test Loss: 0.0006 | LR: 0.001000 | Time: 0.12 sec\n",
      "Epoch 874 | Train Loss: 0.0005 | Test Loss: 0.0006 | LR: 0.001000 | Time: 0.11 sec\n",
      "Epoch 875 | Train Loss: 0.0005 | Test Loss: 0.0006 | LR: 0.001000 | Time: 0.12 sec\n",
      "Epoch 876 | Train Loss: 0.0005 | Test Loss: 0.0006 | LR: 0.001000 | Time: 0.13 sec\n",
      "New best model found at epoch 876, saving checkpoint...\n",
      "Epoch 877 | Train Loss: 0.0005 | Test Loss: 0.0006 | LR: 0.001000 | Time: 0.12 sec\n",
      "New best model found at epoch 877, saving checkpoint...\n",
      "Epoch 878 | Train Loss: 0.0005 | Test Loss: 0.0006 | LR: 0.001000 | Time: 0.15 sec\n",
      "New best model found at epoch 878, saving checkpoint...\n",
      "Epoch 879 | Train Loss: 0.0005 | Test Loss: 0.0006 | LR: 0.001000 | Time: 0.12 sec\n",
      "Epoch 880 | Train Loss: 0.0005 | Test Loss: 0.0006 | LR: 0.001000 | Time: 0.13 sec\n",
      "New best model found at epoch 880, saving checkpoint...\n",
      "Epoch 881 | Train Loss: 0.0005 | Test Loss: 0.0005 | LR: 0.001000 | Time: 0.11 sec\n",
      "New best model found at epoch 881, saving checkpoint...\n",
      "Epoch 882 | Train Loss: 0.0005 | Test Loss: 0.0005 | LR: 0.001000 | Time: 0.11 sec\n",
      "New best model found at epoch 882, saving checkpoint...\n",
      "Epoch 883 | Train Loss: 0.0004 | Test Loss: 0.0005 | LR: 0.001000 | Time: 0.11 sec\n",
      "New best model found at epoch 883, saving checkpoint...\n",
      "Epoch 884 | Train Loss: 0.0005 | Test Loss: 0.0005 | LR: 0.001000 | Time: 0.12 sec\n",
      "Epoch 885 | Train Loss: 0.0005 | Test Loss: 0.0005 | LR: 0.001000 | Time: 0.12 sec\n",
      "Epoch 886 | Train Loss: 0.0004 | Test Loss: 0.0005 | LR: 0.001000 | Time: 0.12 sec\n",
      "New best model found at epoch 886, saving checkpoint...\n",
      "Epoch 887 | Train Loss: 0.0004 | Test Loss: 0.0005 | LR: 0.001000 | Time: 0.11 sec\n",
      "New best model found at epoch 887, saving checkpoint...\n",
      "Epoch 888 | Train Loss: 0.0004 | Test Loss: 0.0005 | LR: 0.001000 | Time: 0.11 sec\n",
      "New best model found at epoch 888, saving checkpoint...\n",
      "Epoch 889 | Train Loss: 0.0004 | Test Loss: 0.0005 | LR: 0.001000 | Time: 0.11 sec\n",
      "New best model found at epoch 889, saving checkpoint...\n",
      "Epoch 890 | Train Loss: 0.0004 | Test Loss: 0.0005 | LR: 0.001000 | Time: 0.12 sec\n",
      "New best model found at epoch 890, saving checkpoint...\n",
      "Epoch 891 | Train Loss: 0.0004 | Test Loss: 0.0005 | LR: 0.001000 | Time: 0.12 sec\n",
      "New best model found at epoch 891, saving checkpoint...\n",
      "Epoch 892 | Train Loss: 0.0004 | Test Loss: 0.0005 | LR: 0.001000 | Time: 0.12 sec\n",
      "New best model found at epoch 892, saving checkpoint...\n",
      "Epoch 893 | Train Loss: 0.0004 | Test Loss: 0.0005 | LR: 0.001000 | Time: 0.13 sec\n",
      "New best model found at epoch 893, saving checkpoint...\n",
      "Epoch 894 | Train Loss: 0.0004 | Test Loss: 0.0005 | LR: 0.001000 | Time: 0.14 sec\n",
      "New best model found at epoch 894, saving checkpoint...\n",
      "Epoch 895 | Train Loss: 0.0004 | Test Loss: 0.0005 | LR: 0.001000 | Time: 0.12 sec\n",
      "New best model found at epoch 895, saving checkpoint...\n",
      "Epoch 896 | Train Loss: 0.0004 | Test Loss: 0.0005 | LR: 0.001000 | Time: 0.12 sec\n",
      "New best model found at epoch 896, saving checkpoint...\n",
      "Epoch 897 | Train Loss: 0.0004 | Test Loss: 0.0005 | LR: 0.001000 | Time: 0.12 sec\n",
      "New best model found at epoch 897, saving checkpoint...\n",
      "Epoch 898 | Train Loss: 0.0004 | Test Loss: 0.0005 | LR: 0.001000 | Time: 0.14 sec\n",
      "New best model found at epoch 898, saving checkpoint...\n",
      "Epoch 899 | Train Loss: 0.0004 | Test Loss: 0.0005 | LR: 0.001000 | Time: 0.11 sec\n",
      "New best model found at epoch 899, saving checkpoint...\n",
      "Epoch 900 | Train Loss: 0.0004 | Test Loss: 0.0005 | LR: 0.001000 | Time: 0.13 sec\n",
      "Epoch 901 | Train Loss: 0.0004 | Test Loss: 0.0005 | LR: 0.001000 | Time: 0.14 sec\n",
      "New best model found at epoch 901, saving checkpoint...\n",
      "Epoch 902 | Train Loss: 0.0004 | Test Loss: 0.0005 | LR: 0.001000 | Time: 0.13 sec\n",
      "New best model found at epoch 902, saving checkpoint...\n",
      "Epoch 903 | Train Loss: 0.0004 | Test Loss: 0.0005 | LR: 0.001000 | Time: 0.12 sec\n",
      "Epoch 904 | Train Loss: 0.0004 | Test Loss: 0.0005 | LR: 0.001000 | Time: 0.15 sec\n",
      "Epoch 905 | Train Loss: 0.0004 | Test Loss: 0.0005 | LR: 0.001000 | Time: 0.12 sec\n",
      "New best model found at epoch 905, saving checkpoint...\n",
      "Epoch 906 | Train Loss: 0.0004 | Test Loss: 0.0005 | LR: 0.001000 | Time: 0.13 sec\n",
      "New best model found at epoch 906, saving checkpoint...\n",
      "Epoch 907 | Train Loss: 0.0004 | Test Loss: 0.0005 | LR: 0.001000 | Time: 0.12 sec\n",
      "New best model found at epoch 907, saving checkpoint...\n",
      "Epoch 908 | Train Loss: 0.0004 | Test Loss: 0.0005 | LR: 0.001000 | Time: 0.11 sec\n",
      "New best model found at epoch 908, saving checkpoint...\n",
      "Epoch 909 | Train Loss: 0.0004 | Test Loss: 0.0004 | LR: 0.001000 | Time: 0.15 sec\n",
      "New best model found at epoch 909, saving checkpoint...\n",
      "Epoch 910 | Train Loss: 0.0004 | Test Loss: 0.0004 | LR: 0.001000 | Time: 0.13 sec\n",
      "New best model found at epoch 910, saving checkpoint...\n",
      "Epoch 911 | Train Loss: 0.0004 | Test Loss: 0.0004 | LR: 0.001000 | Time: 0.13 sec\n",
      "Epoch 912 | Train Loss: 0.0004 | Test Loss: 0.0004 | LR: 0.001000 | Time: 0.12 sec\n",
      "New best model found at epoch 912, saving checkpoint...\n",
      "Epoch 913 | Train Loss: 0.0004 | Test Loss: 0.0004 | LR: 0.001000 | Time: 0.11 sec\n",
      "New best model found at epoch 913, saving checkpoint...\n",
      "Epoch 914 | Train Loss: 0.0004 | Test Loss: 0.0004 | LR: 0.001000 | Time: 0.12 sec\n",
      "New best model found at epoch 914, saving checkpoint...\n",
      "Epoch 915 | Train Loss: 0.0004 | Test Loss: 0.0004 | LR: 0.001000 | Time: 0.11 sec\n",
      "Epoch 916 | Train Loss: 0.0004 | Test Loss: 0.0004 | LR: 0.001000 | Time: 0.11 sec\n",
      "New best model found at epoch 916, saving checkpoint...\n",
      "Epoch 917 | Train Loss: 0.0004 | Test Loss: 0.0004 | LR: 0.001000 | Time: 0.13 sec\n",
      "New best model found at epoch 917, saving checkpoint...\n",
      "Epoch 918 | Train Loss: 0.0003 | Test Loss: 0.0004 | LR: 0.001000 | Time: 0.13 sec\n",
      "New best model found at epoch 918, saving checkpoint...\n",
      "Epoch 919 | Train Loss: 0.0003 | Test Loss: 0.0004 | LR: 0.001000 | Time: 0.13 sec\n",
      "Epoch 920 | Train Loss: 0.0004 | Test Loss: 0.0004 | LR: 0.001000 | Time: 0.11 sec\n",
      "New best model found at epoch 920, saving checkpoint...\n",
      "Epoch 921 | Train Loss: 0.0003 | Test Loss: 0.0004 | LR: 0.001000 | Time: 0.12 sec\n",
      "New best model found at epoch 921, saving checkpoint...\n",
      "Epoch 922 | Train Loss: 0.0003 | Test Loss: 0.0004 | LR: 0.001000 | Time: 0.12 sec\n",
      "New best model found at epoch 922, saving checkpoint...\n",
      "Epoch 923 | Train Loss: 0.0003 | Test Loss: 0.0004 | LR: 0.001000 | Time: 0.13 sec\n",
      "New best model found at epoch 923, saving checkpoint...\n",
      "Epoch 924 | Train Loss: 0.0003 | Test Loss: 0.0004 | LR: 0.001000 | Time: 0.13 sec\n",
      "Epoch 925 | Train Loss: 0.0003 | Test Loss: 0.0004 | LR: 0.001000 | Time: 0.11 sec\n",
      "Epoch 926 | Train Loss: 0.0003 | Test Loss: 0.0004 | LR: 0.001000 | Time: 0.18 sec\n",
      "New best model found at epoch 926, saving checkpoint...\n",
      "Epoch 927 | Train Loss: 0.0003 | Test Loss: 0.0004 | LR: 0.001000 | Time: 0.14 sec\n",
      "New best model found at epoch 927, saving checkpoint...\n",
      "Epoch 928 | Train Loss: 0.0003 | Test Loss: 0.0004 | LR: 0.001000 | Time: 0.14 sec\n",
      "Epoch 929 | Train Loss: 0.0003 | Test Loss: 0.0004 | LR: 0.001000 | Time: 0.12 sec\n",
      "New best model found at epoch 929, saving checkpoint...\n",
      "Epoch 930 | Train Loss: 0.0003 | Test Loss: 0.0004 | LR: 0.001000 | Time: 0.12 sec\n",
      "Epoch 931 | Train Loss: 0.0003 | Test Loss: 0.0004 | LR: 0.001000 | Time: 0.12 sec\n",
      "Epoch 932 | Train Loss: 0.0003 | Test Loss: 0.0004 | LR: 0.001000 | Time: 0.12 sec\n",
      "Epoch 933 | Train Loss: 0.0003 | Test Loss: 0.0004 | LR: 0.001000 | Time: 0.12 sec\n",
      "Epoch 934 | Train Loss: 0.0003 | Test Loss: 0.0004 | LR: 0.001000 | Time: 0.12 sec\n",
      "Epoch 935 | Train Loss: 0.0003 | Test Loss: 0.0004 | LR: 0.001000 | Time: 0.13 sec\n",
      "New best model found at epoch 935, saving checkpoint...\n",
      "Epoch 936 | Train Loss: 0.0003 | Test Loss: 0.0004 | LR: 0.001000 | Time: 0.15 sec\n",
      "New best model found at epoch 936, saving checkpoint...\n",
      "Epoch 937 | Train Loss: 0.0003 | Test Loss: 0.0004 | LR: 0.001000 | Time: 0.14 sec\n",
      "New best model found at epoch 937, saving checkpoint...\n",
      "Epoch 938 | Train Loss: 0.0003 | Test Loss: 0.0004 | LR: 0.001000 | Time: 0.12 sec\n",
      "Epoch 939 | Train Loss: 0.0003 | Test Loss: 0.0004 | LR: 0.001000 | Time: 0.13 sec\n",
      "Epoch 940 | Train Loss: 0.0003 | Test Loss: 0.0004 | LR: 0.001000 | Time: 0.14 sec\n",
      "New best model found at epoch 940, saving checkpoint...\n",
      "Epoch 941 | Train Loss: 0.0003 | Test Loss: 0.0004 | LR: 0.001000 | Time: 0.13 sec\n",
      "Epoch 942 | Train Loss: 0.0003 | Test Loss: 0.0004 | LR: 0.001000 | Time: 0.15 sec\n",
      "New best model found at epoch 942, saving checkpoint...\n",
      "Epoch 943 | Train Loss: 0.0003 | Test Loss: 0.0004 | LR: 0.001000 | Time: 0.12 sec\n",
      "New best model found at epoch 943, saving checkpoint...\n",
      "Epoch 944 | Train Loss: 0.0003 | Test Loss: 0.0004 | LR: 0.001000 | Time: 0.13 sec\n",
      "New best model found at epoch 944, saving checkpoint...\n",
      "Epoch 945 | Train Loss: 0.0003 | Test Loss: 0.0004 | LR: 0.001000 | Time: 0.16 sec\n",
      "Epoch 946 | Train Loss: 0.0003 | Test Loss: 0.0004 | LR: 0.001000 | Time: 0.12 sec\n",
      "New best model found at epoch 946, saving checkpoint...\n",
      "Epoch 947 | Train Loss: 0.0003 | Test Loss: 0.0004 | LR: 0.001000 | Time: 0.13 sec\n",
      "Epoch 948 | Train Loss: 0.0003 | Test Loss: 0.0004 | LR: 0.001000 | Time: 0.13 sec\n",
      "New best model found at epoch 948, saving checkpoint...\n",
      "Epoch 949 | Train Loss: 0.0003 | Test Loss: 0.0003 | LR: 0.001000 | Time: 0.12 sec\n",
      "New best model found at epoch 949, saving checkpoint...\n",
      "Epoch 950 | Train Loss: 0.0003 | Test Loss: 0.0003 | LR: 0.001000 | Time: 0.13 sec\n",
      "New best model found at epoch 950, saving checkpoint...\n",
      "Epoch 951 | Train Loss: 0.0003 | Test Loss: 0.0003 | LR: 0.001000 | Time: 0.13 sec\n",
      "New best model found at epoch 951, saving checkpoint...\n",
      "Epoch 952 | Train Loss: 0.0003 | Test Loss: 0.0003 | LR: 0.001000 | Time: 0.12 sec\n",
      "New best model found at epoch 952, saving checkpoint...\n",
      "Epoch 953 | Train Loss: 0.0003 | Test Loss: 0.0003 | LR: 0.001000 | Time: 0.12 sec\n",
      "New best model found at epoch 953, saving checkpoint...\n",
      "Epoch 954 | Train Loss: 0.0003 | Test Loss: 0.0003 | LR: 0.001000 | Time: 0.15 sec\n",
      "New best model found at epoch 954, saving checkpoint...\n",
      "Epoch 955 | Train Loss: 0.0003 | Test Loss: 0.0003 | LR: 0.001000 | Time: 0.13 sec\n",
      "New best model found at epoch 955, saving checkpoint...\n",
      "Epoch 956 | Train Loss: 0.0003 | Test Loss: 0.0003 | LR: 0.001000 | Time: 0.12 sec\n",
      "Epoch 957 | Train Loss: 0.0003 | Test Loss: 0.0003 | LR: 0.001000 | Time: 0.12 sec\n",
      "Epoch 958 | Train Loss: 0.0003 | Test Loss: 0.0003 | LR: 0.001000 | Time: 0.12 sec\n",
      "Epoch 959 | Train Loss: 0.0003 | Test Loss: 0.0004 | LR: 0.001000 | Time: 0.13 sec\n",
      "Epoch 960 | Train Loss: 0.0003 | Test Loss: 0.0003 | LR: 0.001000 | Time: 0.13 sec\n",
      "New best model found at epoch 960, saving checkpoint...\n",
      "Epoch 961 | Train Loss: 0.0003 | Test Loss: 0.0003 | LR: 0.001000 | Time: 0.13 sec\n",
      "Epoch 962 | Train Loss: 0.0003 | Test Loss: 0.0003 | LR: 0.001000 | Time: 0.12 sec\n",
      "Epoch 963 | Train Loss: 0.0003 | Test Loss: 0.0003 | LR: 0.001000 | Time: 0.15 sec\n",
      "New best model found at epoch 963, saving checkpoint...\n",
      "Epoch 964 | Train Loss: 0.0003 | Test Loss: 0.0003 | LR: 0.001000 | Time: 0.13 sec\n",
      "Epoch 965 | Train Loss: 0.0003 | Test Loss: 0.0003 | LR: 0.001000 | Time: 0.17 sec\n",
      "Epoch 966 | Train Loss: 0.0003 | Test Loss: 0.0003 | LR: 0.001000 | Time: 0.12 sec\n",
      "Epoch 967 | Train Loss: 0.0003 | Test Loss: 0.0003 | LR: 0.001000 | Time: 0.12 sec\n",
      "Epoch 968 | Train Loss: 0.0003 | Test Loss: 0.0003 | LR: 0.001000 | Time: 0.12 sec\n",
      "Epoch 969 | Train Loss: 0.0003 | Test Loss: 0.0003 | LR: 0.001000 | Time: 0.12 sec\n",
      "New best model found at epoch 969, saving checkpoint...\n",
      "Epoch 970 | Train Loss: 0.0003 | Test Loss: 0.0003 | LR: 0.001000 | Time: 0.13 sec\n",
      "New best model found at epoch 970, saving checkpoint...\n",
      "Epoch 971 | Train Loss: 0.0003 | Test Loss: 0.0003 | LR: 0.001000 | Time: 0.12 sec\n",
      "Epoch 972 | Train Loss: 0.0003 | Test Loss: 0.0003 | LR: 0.001000 | Time: 0.13 sec\n",
      "Epoch 973 | Train Loss: 0.0003 | Test Loss: 0.0003 | LR: 0.001000 | Time: 0.13 sec\n",
      "New best model found at epoch 973, saving checkpoint...\n",
      "Epoch 974 | Train Loss: 0.0003 | Test Loss: 0.0003 | LR: 0.001000 | Time: 0.13 sec\n",
      "New best model found at epoch 974, saving checkpoint...\n",
      "Epoch 975 | Train Loss: 0.0003 | Test Loss: 0.0003 | LR: 0.001000 | Time: 0.14 sec\n",
      "New best model found at epoch 975, saving checkpoint...\n",
      "Epoch 976 | Train Loss: 0.0003 | Test Loss: 0.0003 | LR: 0.001000 | Time: 0.12 sec\n",
      "Epoch 977 | Train Loss: 0.0003 | Test Loss: 0.0003 | LR: 0.001000 | Time: 0.15 sec\n",
      "Epoch 978 | Train Loss: 0.0003 | Test Loss: 0.0003 | LR: 0.001000 | Time: 0.12 sec\n",
      "New best model found at epoch 978, saving checkpoint...\n",
      "Epoch 979 | Train Loss: 0.0003 | Test Loss: 0.0003 | LR: 0.001000 | Time: 0.13 sec\n",
      "New best model found at epoch 979, saving checkpoint...\n",
      "Epoch 980 | Train Loss: 0.0003 | Test Loss: 0.0003 | LR: 0.001000 | Time: 0.13 sec\n",
      "New best model found at epoch 980, saving checkpoint...\n",
      "Epoch 981 | Train Loss: 0.0002 | Test Loss: 0.0003 | LR: 0.001000 | Time: 0.13 sec\n",
      "New best model found at epoch 981, saving checkpoint...\n",
      "Epoch 982 | Train Loss: 0.0003 | Test Loss: 0.0003 | LR: 0.001000 | Time: 0.13 sec\n",
      "Epoch 983 | Train Loss: 0.0003 | Test Loss: 0.0003 | LR: 0.001000 | Time: 0.13 sec\n",
      "Epoch 984 | Train Loss: 0.0003 | Test Loss: 0.0003 | LR: 0.001000 | Time: 0.13 sec\n",
      "Epoch 985 | Train Loss: 0.0003 | Test Loss: 0.0003 | LR: 0.001000 | Time: 0.12 sec\n",
      "Epoch 986 | Train Loss: 0.0002 | Test Loss: 0.0003 | LR: 0.001000 | Time: 0.15 sec\n",
      "New best model found at epoch 986, saving checkpoint...\n",
      "Epoch 987 | Train Loss: 0.0002 | Test Loss: 0.0003 | LR: 0.001000 | Time: 0.13 sec\n",
      "Epoch 988 | Train Loss: 0.0002 | Test Loss: 0.0003 | LR: 0.001000 | Time: 0.13 sec\n",
      "Epoch 989 | Train Loss: 0.0002 | Test Loss: 0.0003 | LR: 0.001000 | Time: 0.13 sec\n",
      "New best model found at epoch 989, saving checkpoint...\n",
      "Epoch 990 | Train Loss: 0.0002 | Test Loss: 0.0003 | LR: 0.001000 | Time: 0.12 sec\n",
      "New best model found at epoch 990, saving checkpoint...\n",
      "Epoch 991 | Train Loss: 0.0002 | Test Loss: 0.0003 | LR: 0.001000 | Time: 0.14 sec\n",
      "Epoch 992 | Train Loss: 0.0002 | Test Loss: 0.0003 | LR: 0.001000 | Time: 0.13 sec\n",
      "Epoch 993 | Train Loss: 0.0002 | Test Loss: 0.0003 | LR: 0.001000 | Time: 0.13 sec\n",
      "Epoch 994 | Train Loss: 0.0002 | Test Loss: 0.0003 | LR: 0.001000 | Time: 0.13 sec\n",
      "Epoch 995 | Train Loss: 0.0002 | Test Loss: 0.0003 | LR: 0.001000 | Time: 0.13 sec\n",
      "New best model found at epoch 995, saving checkpoint...\n",
      "Epoch 996 | Train Loss: 0.0002 | Test Loss: 0.0003 | LR: 0.001000 | Time: 0.14 sec\n",
      "New best model found at epoch 996, saving checkpoint...\n",
      "Epoch 997 | Train Loss: 0.0002 | Test Loss: 0.0003 | LR: 0.001000 | Time: 0.13 sec\n",
      "Epoch 998 | Train Loss: 0.0002 | Test Loss: 0.0003 | LR: 0.001000 | Time: 0.14 sec\n",
      "Epoch 999 | Train Loss: 0.0002 | Test Loss: 0.0003 | LR: 0.001000 | Time: 0.13 sec\n",
      "Epoch 1000 | Train Loss: 0.0002 | Test Loss: 0.0003 | LR: 0.001000 | Time: 0.12 sec\n",
      "Epoch 1001 | Train Loss: 0.0002 | Test Loss: 0.0003 | LR: 0.001000 | Time: 0.13 sec\n",
      "New best model found at epoch 1001, saving checkpoint...\n",
      "Epoch 1002 | Train Loss: 0.0002 | Test Loss: 0.0003 | LR: 0.001000 | Time: 0.14 sec\n",
      "New best model found at epoch 1002, saving checkpoint...\n",
      "Epoch 1003 | Train Loss: 0.0002 | Test Loss: 0.0003 | LR: 0.001000 | Time: 0.13 sec\n",
      "New best model found at epoch 1003, saving checkpoint...\n",
      "Epoch 1004 | Train Loss: 0.0002 | Test Loss: 0.0003 | LR: 0.001000 | Time: 0.13 sec\n",
      "Epoch 1005 | Train Loss: 0.0002 | Test Loss: 0.0003 | LR: 0.001000 | Time: 0.13 sec\n",
      "Epoch 1006 | Train Loss: 0.0002 | Test Loss: 0.0003 | LR: 0.001000 | Time: 0.14 sec\n",
      "New best model found at epoch 1006, saving checkpoint...\n",
      "Epoch 1007 | Train Loss: 0.0002 | Test Loss: 0.0003 | LR: 0.001000 | Time: 0.13 sec\n",
      "New best model found at epoch 1007, saving checkpoint...\n",
      "Epoch 1008 | Train Loss: 0.0002 | Test Loss: 0.0003 | LR: 0.001000 | Time: 0.14 sec\n",
      "New best model found at epoch 1008, saving checkpoint...\n",
      "Epoch 1009 | Train Loss: 0.0002 | Test Loss: 0.0003 | LR: 0.001000 | Time: 0.13 sec\n",
      "Epoch 1010 | Train Loss: 0.0002 | Test Loss: 0.0003 | LR: 0.001000 | Time: 0.13 sec\n",
      "New best model found at epoch 1010, saving checkpoint...\n",
      "Epoch 1011 | Train Loss: 0.0002 | Test Loss: 0.0003 | LR: 0.001000 | Time: 0.13 sec\n",
      "Epoch 1012 | Train Loss: 0.0002 | Test Loss: 0.0003 | LR: 0.001000 | Time: 0.12 sec\n",
      "New best model found at epoch 1012, saving checkpoint...\n",
      "Epoch 1013 | Train Loss: 0.0002 | Test Loss: 0.0003 | LR: 0.001000 | Time: 0.12 sec\n",
      "Epoch 1014 | Train Loss: 0.0002 | Test Loss: 0.0003 | LR: 0.001000 | Time: 0.13 sec\n",
      "Epoch 1015 | Train Loss: 0.0002 | Test Loss: 0.0003 | LR: 0.001000 | Time: 0.13 sec\n",
      "New best model found at epoch 1015, saving checkpoint...\n",
      "Epoch 1016 | Train Loss: 0.0002 | Test Loss: 0.0003 | LR: 0.001000 | Time: 0.12 sec\n",
      "New best model found at epoch 1016, saving checkpoint...\n",
      "Epoch 1017 | Train Loss: 0.0002 | Test Loss: 0.0003 | LR: 0.001000 | Time: 0.12 sec\n",
      "Epoch 1018 | Train Loss: 0.0002 | Test Loss: 0.0003 | LR: 0.001000 | Time: 0.15 sec\n",
      "New best model found at epoch 1018, saving checkpoint...\n",
      "Epoch 1019 | Train Loss: 0.0002 | Test Loss: 0.0003 | LR: 0.001000 | Time: 0.15 sec\n",
      "New best model found at epoch 1019, saving checkpoint...\n",
      "Epoch 1020 | Train Loss: 0.0002 | Test Loss: 0.0003 | LR: 0.001000 | Time: 0.14 sec\n",
      "New best model found at epoch 1020, saving checkpoint...\n",
      "Epoch 1021 | Train Loss: 0.0002 | Test Loss: 0.0003 | LR: 0.001000 | Time: 0.16 sec\n",
      "New best model found at epoch 1021, saving checkpoint...\n",
      "Epoch 1022 | Train Loss: 0.0002 | Test Loss: 0.0003 | LR: 0.001000 | Time: 0.13 sec\n",
      "New best model found at epoch 1022, saving checkpoint...\n",
      "Epoch 1023 | Train Loss: 0.0002 | Test Loss: 0.0003 | LR: 0.001000 | Time: 0.12 sec\n",
      "Epoch 1024 | Train Loss: 0.0002 | Test Loss: 0.0003 | LR: 0.001000 | Time: 0.12 sec\n",
      "Epoch 1025 | Train Loss: 0.0002 | Test Loss: 0.0003 | LR: 0.001000 | Time: 0.14 sec\n",
      "Epoch 1026 | Train Loss: 0.0002 | Test Loss: 0.0003 | LR: 0.001000 | Time: 0.13 sec\n",
      "Epoch 1027 | Train Loss: 0.0002 | Test Loss: 0.0003 | LR: 0.001000 | Time: 0.15 sec\n",
      "Epoch 1028 | Train Loss: 0.0002 | Test Loss: 0.0002 | LR: 0.001000 | Time: 0.12 sec\n",
      "New best model found at epoch 1028, saving checkpoint...\n",
      "Epoch 1029 | Train Loss: 0.0002 | Test Loss: 0.0002 | LR: 0.001000 | Time: 0.12 sec\n",
      "New best model found at epoch 1029, saving checkpoint...\n",
      "Epoch 1030 | Train Loss: 0.0002 | Test Loss: 0.0002 | LR: 0.001000 | Time: 0.12 sec\n",
      "Epoch 1031 | Train Loss: 0.0002 | Test Loss: 0.0002 | LR: 0.001000 | Time: 0.13 sec\n",
      "New best model found at epoch 1031, saving checkpoint...\n",
      "Epoch 1032 | Train Loss: 0.0002 | Test Loss: 0.0002 | LR: 0.001000 | Time: 0.13 sec\n",
      "Epoch 1033 | Train Loss: 0.0002 | Test Loss: 0.0002 | LR: 0.001000 | Time: 0.13 sec\n",
      "Epoch 1034 | Train Loss: 0.0002 | Test Loss: 0.0002 | LR: 0.001000 | Time: 0.13 sec\n",
      "New best model found at epoch 1034, saving checkpoint...\n",
      "Epoch 1035 | Train Loss: 0.0002 | Test Loss: 0.0002 | LR: 0.001000 | Time: 0.12 sec\n",
      "New best model found at epoch 1035, saving checkpoint...\n",
      "Epoch 1036 | Train Loss: 0.0002 | Test Loss: 0.0002 | LR: 0.001000 | Time: 0.13 sec\n",
      "New best model found at epoch 1036, saving checkpoint...\n",
      "Epoch 1037 | Train Loss: 0.0002 | Test Loss: 0.0002 | LR: 0.001000 | Time: 0.13 sec\n",
      "Epoch 1038 | Train Loss: 0.0002 | Test Loss: 0.0002 | LR: 0.001000 | Time: 0.13 sec\n",
      "New best model found at epoch 1038, saving checkpoint...\n",
      "Epoch 1039 | Train Loss: 0.0002 | Test Loss: 0.0002 | LR: 0.001000 | Time: 0.12 sec\n",
      "Epoch 1040 | Train Loss: 0.0002 | Test Loss: 0.0002 | LR: 0.001000 | Time: 0.14 sec\n",
      "New best model found at epoch 1040, saving checkpoint...\n",
      "Epoch 1041 | Train Loss: 0.0002 | Test Loss: 0.0002 | LR: 0.001000 | Time: 0.12 sec\n",
      "Epoch 1042 | Train Loss: 0.0002 | Test Loss: 0.0002 | LR: 0.001000 | Time: 0.12 sec\n",
      "New best model found at epoch 1042, saving checkpoint...\n",
      "Epoch 1043 | Train Loss: 0.0002 | Test Loss: 0.0002 | LR: 0.001000 | Time: 0.12 sec\n",
      "New best model found at epoch 1043, saving checkpoint...\n",
      "Epoch 1044 | Train Loss: 0.0002 | Test Loss: 0.0002 | LR: 0.001000 | Time: 0.12 sec\n",
      "New best model found at epoch 1044, saving checkpoint...\n",
      "Epoch 1045 | Train Loss: 0.0002 | Test Loss: 0.0002 | LR: 0.001000 | Time: 0.12 sec\n",
      "Epoch 1046 | Train Loss: 0.0002 | Test Loss: 0.0002 | LR: 0.001000 | Time: 0.13 sec\n",
      "New best model found at epoch 1046, saving checkpoint...\n",
      "Epoch 1047 | Train Loss: 0.0002 | Test Loss: 0.0002 | LR: 0.001000 | Time: 0.12 sec\n",
      "New best model found at epoch 1047, saving checkpoint...\n",
      "Epoch 1048 | Train Loss: 0.0002 | Test Loss: 0.0002 | LR: 0.001000 | Time: 0.12 sec\n",
      "New best model found at epoch 1048, saving checkpoint...\n",
      "Epoch 1049 | Train Loss: 0.0002 | Test Loss: 0.0002 | LR: 0.001000 | Time: 0.12 sec\n",
      "New best model found at epoch 1049, saving checkpoint...\n",
      "Epoch 1050 | Train Loss: 0.0002 | Test Loss: 0.0002 | LR: 0.001000 | Time: 0.12 sec\n",
      "Epoch 1051 | Train Loss: 0.0002 | Test Loss: 0.0002 | LR: 0.001000 | Time: 0.12 sec\n",
      "New best model found at epoch 1051, saving checkpoint...\n",
      "Epoch 1052 | Train Loss: 0.0002 | Test Loss: 0.0002 | LR: 0.001000 | Time: 0.12 sec\n",
      "New best model found at epoch 1052, saving checkpoint...\n",
      "Epoch 1053 | Train Loss: 0.0002 | Test Loss: 0.0002 | LR: 0.001000 | Time: 0.12 sec\n",
      "New best model found at epoch 1053, saving checkpoint...\n",
      "Epoch 1054 | Train Loss: 0.0002 | Test Loss: 0.0002 | LR: 0.001000 | Time: 0.11 sec\n",
      "Epoch 1055 | Train Loss: 0.0002 | Test Loss: 0.0002 | LR: 0.001000 | Time: 0.11 sec\n",
      "Epoch 1056 | Train Loss: 0.0002 | Test Loss: 0.0002 | LR: 0.001000 | Time: 0.12 sec\n",
      "Epoch 1057 | Train Loss: 0.0002 | Test Loss: 0.0002 | LR: 0.001000 | Time: 0.13 sec\n",
      "Epoch 1058 | Train Loss: 0.0002 | Test Loss: 0.0002 | LR: 0.001000 | Time: 0.12 sec\n",
      "Epoch 1059 | Train Loss: 0.0002 | Test Loss: 0.0002 | LR: 0.001000 | Time: 0.11 sec\n",
      "New best model found at epoch 1059, saving checkpoint...\n",
      "Epoch 1060 | Train Loss: 0.0002 | Test Loss: 0.0002 | LR: 0.001000 | Time: 0.11 sec\n",
      "New best model found at epoch 1060, saving checkpoint...\n",
      "Epoch 1061 | Train Loss: 0.0002 | Test Loss: 0.0002 | LR: 0.001000 | Time: 0.11 sec\n",
      "Epoch 1062 | Train Loss: 0.0002 | Test Loss: 0.0002 | LR: 0.001000 | Time: 0.12 sec\n",
      "Epoch 1063 | Train Loss: 0.0002 | Test Loss: 0.0002 | LR: 0.001000 | Time: 0.13 sec\n",
      "Epoch 1064 | Train Loss: 0.0002 | Test Loss: 0.0002 | LR: 0.001000 | Time: 0.12 sec\n",
      "Epoch 1065 | Train Loss: 0.0002 | Test Loss: 0.0002 | LR: 0.001000 | Time: 0.12 sec\n",
      "New best model found at epoch 1065, saving checkpoint...\n",
      "Epoch 1066 | Train Loss: 0.0002 | Test Loss: 0.0002 | LR: 0.001000 | Time: 0.11 sec\n",
      "New best model found at epoch 1066, saving checkpoint...\n",
      "Epoch 1067 | Train Loss: 0.0002 | Test Loss: 0.0002 | LR: 0.001000 | Time: 0.12 sec\n",
      "New best model found at epoch 1067, saving checkpoint...\n",
      "Epoch 1068 | Train Loss: 0.0002 | Test Loss: 0.0002 | LR: 0.001000 | Time: 0.13 sec\n",
      "Epoch 1069 | Train Loss: 0.0002 | Test Loss: 0.0002 | LR: 0.001000 | Time: 0.13 sec\n",
      "Epoch 1070 | Train Loss: 0.0002 | Test Loss: 0.0002 | LR: 0.001000 | Time: 0.13 sec\n",
      "New best model found at epoch 1070, saving checkpoint...\n",
      "Epoch 1071 | Train Loss: 0.0002 | Test Loss: 0.0002 | LR: 0.001000 | Time: 0.13 sec\n",
      "Epoch 1072 | Train Loss: 0.0002 | Test Loss: 0.0002 | LR: 0.001000 | Time: 0.14 sec\n",
      "New best model found at epoch 1072, saving checkpoint...\n",
      "Epoch 1073 | Train Loss: 0.0002 | Test Loss: 0.0002 | LR: 0.001000 | Time: 0.12 sec\n",
      "New best model found at epoch 1073, saving checkpoint...\n",
      "Epoch 1074 | Train Loss: 0.0002 | Test Loss: 0.0002 | LR: 0.001000 | Time: 0.13 sec\n",
      "Epoch 1075 | Train Loss: 0.0002 | Test Loss: 0.0002 | LR: 0.001000 | Time: 0.11 sec\n",
      "New best model found at epoch 1075, saving checkpoint...\n",
      "Epoch 1076 | Train Loss: 0.0002 | Test Loss: 0.0002 | LR: 0.001000 | Time: 0.12 sec\n",
      "Epoch 1077 | Train Loss: 0.0002 | Test Loss: 0.0002 | LR: 0.001000 | Time: 0.12 sec\n",
      "Epoch 1078 | Train Loss: 0.0002 | Test Loss: 0.0002 | LR: 0.001000 | Time: 0.12 sec\n",
      "Epoch 1079 | Train Loss: 0.0002 | Test Loss: 0.0002 | LR: 0.001000 | Time: 0.13 sec\n",
      "Epoch 1080 | Train Loss: 0.0002 | Test Loss: 0.0002 | LR: 0.001000 | Time: 0.14 sec\n",
      "New best model found at epoch 1080, saving checkpoint...\n",
      "Epoch 1081 | Train Loss: 0.0002 | Test Loss: 0.0002 | LR: 0.001000 | Time: 0.13 sec\n",
      "Epoch 1082 | Train Loss: 0.0002 | Test Loss: 0.0002 | LR: 0.001000 | Time: 0.12 sec\n",
      "Epoch 1083 | Train Loss: 0.0001 | Test Loss: 0.0002 | LR: 0.001000 | Time: 0.12 sec\n",
      "Epoch 1084 | Train Loss: 0.0002 | Test Loss: 0.0002 | LR: 0.001000 | Time: 0.13 sec\n",
      "Epoch 1085 | Train Loss: 0.0002 | Test Loss: 0.0002 | LR: 0.001000 | Time: 0.12 sec\n",
      "New best model found at epoch 1085, saving checkpoint...\n",
      "Epoch 1086 | Train Loss: 0.0001 | Test Loss: 0.0002 | LR: 0.001000 | Time: 0.13 sec\n",
      "New best model found at epoch 1086, saving checkpoint...\n",
      "Epoch 1087 | Train Loss: 0.0001 | Test Loss: 0.0002 | LR: 0.001000 | Time: 0.12 sec\n",
      "New best model found at epoch 1087, saving checkpoint...\n",
      "Epoch 1088 | Train Loss: 0.0002 | Test Loss: 0.0002 | LR: 0.001000 | Time: 0.12 sec\n",
      "New best model found at epoch 1088, saving checkpoint...\n",
      "Epoch 1089 | Train Loss: 0.0001 | Test Loss: 0.0002 | LR: 0.001000 | Time: 0.87 sec\n",
      "New best model found at epoch 1089, saving checkpoint...\n",
      "Epoch 1090 | Train Loss: 0.0001 | Test Loss: 0.0002 | LR: 0.001000 | Time: 0.13 sec\n",
      "Epoch 1091 | Train Loss: 0.0002 | Test Loss: 0.0002 | LR: 0.001000 | Time: 0.12 sec\n",
      "New best model found at epoch 1091, saving checkpoint...\n",
      "Epoch 1092 | Train Loss: 0.0001 | Test Loss: 0.0002 | LR: 0.001000 | Time: 0.13 sec\n",
      "Epoch 1093 | Train Loss: 0.0001 | Test Loss: 0.0002 | LR: 0.001000 | Time: 0.12 sec\n",
      "New best model found at epoch 1093, saving checkpoint...\n",
      "Epoch 1094 | Train Loss: 0.0001 | Test Loss: 0.0002 | LR: 0.001000 | Time: 0.12 sec\n",
      "New best model found at epoch 1094, saving checkpoint...\n",
      "Epoch 1095 | Train Loss: 0.0001 | Test Loss: 0.0002 | LR: 0.001000 | Time: 0.13 sec\n",
      "Epoch 1096 | Train Loss: 0.0001 | Test Loss: 0.0002 | LR: 0.001000 | Time: 0.13 sec\n",
      "Epoch 1097 | Train Loss: 0.0001 | Test Loss: 0.0002 | LR: 0.001000 | Time: 0.13 sec\n",
      "Epoch 1098 | Train Loss: 0.0001 | Test Loss: 0.0002 | LR: 0.001000 | Time: 0.12 sec\n",
      "New best model found at epoch 1098, saving checkpoint...\n",
      "Epoch 1099 | Train Loss: 0.0001 | Test Loss: 0.0002 | LR: 0.001000 | Time: 0.12 sec\n",
      "New best model found at epoch 1099, saving checkpoint...\n",
      "Epoch 1100 | Train Loss: 0.0001 | Test Loss: 0.0002 | LR: 0.001000 | Time: 0.13 sec\n",
      "Epoch 1101 | Train Loss: 0.0001 | Test Loss: 0.0002 | LR: 0.001000 | Time: 0.12 sec\n",
      "New best model found at epoch 1101, saving checkpoint...\n",
      "Epoch 1102 | Train Loss: 0.0001 | Test Loss: 0.0002 | LR: 0.001000 | Time: 0.13 sec\n",
      "Epoch 1103 | Train Loss: 0.0001 | Test Loss: 0.0002 | LR: 0.001000 | Time: 0.13 sec\n",
      "New best model found at epoch 1103, saving checkpoint...\n",
      "Epoch 1104 | Train Loss: 0.0001 | Test Loss: 0.0002 | LR: 0.001000 | Time: 0.12 sec\n",
      "Epoch 1105 | Train Loss: 0.0001 | Test Loss: 0.0002 | LR: 0.001000 | Time: 0.12 sec\n",
      "Epoch 1106 | Train Loss: 0.0001 | Test Loss: 0.0002 | LR: 0.001000 | Time: 0.12 sec\n",
      "New best model found at epoch 1106, saving checkpoint...\n",
      "Epoch 1107 | Train Loss: 0.0001 | Test Loss: 0.0002 | LR: 0.001000 | Time: 0.13 sec\n",
      "New best model found at epoch 1107, saving checkpoint...\n",
      "Epoch 1108 | Train Loss: 0.0001 | Test Loss: 0.0002 | LR: 0.001000 | Time: 0.12 sec\n",
      "Epoch 1109 | Train Loss: 0.0001 | Test Loss: 0.0002 | LR: 0.001000 | Time: 0.12 sec\n",
      "Epoch 1110 | Train Loss: 0.0001 | Test Loss: 0.0002 | LR: 0.001000 | Time: 0.13 sec\n",
      "New best model found at epoch 1110, saving checkpoint...\n",
      "Epoch 1111 | Train Loss: 0.0001 | Test Loss: 0.0002 | LR: 0.001000 | Time: 0.13 sec\n",
      "New best model found at epoch 1111, saving checkpoint...\n",
      "Epoch 1112 | Train Loss: 0.0001 | Test Loss: 0.0002 | LR: 0.001000 | Time: 0.15 sec\n",
      "Epoch 1113 | Train Loss: 0.0001 | Test Loss: 0.0002 | LR: 0.001000 | Time: 0.15 sec\n",
      "Epoch 1114 | Train Loss: 0.0001 | Test Loss: 0.0002 | LR: 0.001000 | Time: 0.13 sec\n",
      "New best model found at epoch 1114, saving checkpoint...\n",
      "Epoch 1115 | Train Loss: 0.0001 | Test Loss: 0.0002 | LR: 0.001000 | Time: 0.13 sec\n",
      "Epoch 1116 | Train Loss: 0.0001 | Test Loss: 0.0002 | LR: 0.001000 | Time: 0.13 sec\n",
      "Epoch 1117 | Train Loss: 0.0001 | Test Loss: 0.0002 | LR: 0.001000 | Time: 0.14 sec\n",
      "New best model found at epoch 1117, saving checkpoint...\n",
      "Epoch 1118 | Train Loss: 0.0001 | Test Loss: 0.0002 | LR: 0.001000 | Time: 0.15 sec\n",
      "Epoch 1119 | Train Loss: 0.0001 | Test Loss: 0.0002 | LR: 0.001000 | Time: 0.14 sec\n",
      "Epoch 1120 | Train Loss: 0.0001 | Test Loss: 0.0002 | LR: 0.001000 | Time: 0.15 sec\n",
      "Epoch 1121 | Train Loss: 0.0001 | Test Loss: 0.0002 | LR: 0.001000 | Time: 0.16 sec\n",
      "New best model found at epoch 1121, saving checkpoint...\n",
      "Epoch 1122 | Train Loss: 0.0001 | Test Loss: 0.0002 | LR: 0.001000 | Time: 0.17 sec\n",
      "Epoch 1123 | Train Loss: 0.0001 | Test Loss: 0.0002 | LR: 0.001000 | Time: 0.15 sec\n",
      "New best model found at epoch 1123, saving checkpoint...\n",
      "Epoch 1124 | Train Loss: 0.0001 | Test Loss: 0.0002 | LR: 0.001000 | Time: 0.15 sec\n",
      "New best model found at epoch 1124, saving checkpoint...\n",
      "Epoch 1125 | Train Loss: 0.0001 | Test Loss: 0.0002 | LR: 0.001000 | Time: 0.16 sec\n",
      "Epoch 1126 | Train Loss: 0.0001 | Test Loss: 0.0002 | LR: 0.001000 | Time: 0.15 sec\n",
      "Epoch 1127 | Train Loss: 0.0001 | Test Loss: 0.0002 | LR: 0.001000 | Time: 0.17 sec\n",
      "Epoch 1128 | Train Loss: 0.0001 | Test Loss: 0.0002 | LR: 0.001000 | Time: 0.15 sec\n",
      "Epoch 1129 | Train Loss: 0.0001 | Test Loss: 0.0002 | LR: 0.001000 | Time: 0.13 sec\n",
      "Epoch 1130 | Train Loss: 0.0001 | Test Loss: 0.0002 | LR: 0.001000 | Time: 0.15 sec\n",
      "New best model found at epoch 1130, saving checkpoint...\n",
      "Epoch 1131 | Train Loss: 0.0001 | Test Loss: 0.0002 | LR: 0.001000 | Time: 0.15 sec\n",
      "Epoch 1132 | Train Loss: 0.0001 | Test Loss: 0.0002 | LR: 0.001000 | Time: 0.15 sec\n",
      "Epoch 1133 | Train Loss: 0.0001 | Test Loss: 0.0002 | LR: 0.001000 | Time: 0.17 sec\n",
      "Epoch 1134 | Train Loss: 0.0001 | Test Loss: 0.0002 | LR: 0.001000 | Time: 0.14 sec\n",
      "New best model found at epoch 1134, saving checkpoint...\n",
      "Epoch 1135 | Train Loss: 0.0001 | Test Loss: 0.0002 | LR: 0.001000 | Time: 0.15 sec\n",
      "New best model found at epoch 1135, saving checkpoint...\n",
      "Epoch 1136 | Train Loss: 0.0001 | Test Loss: 0.0002 | LR: 0.001000 | Time: 0.16 sec\n",
      "Epoch 1137 | Train Loss: 0.0001 | Test Loss: 0.0002 | LR: 0.001000 | Time: 0.13 sec\n",
      "New best model found at epoch 1137, saving checkpoint...\n",
      "Epoch 1138 | Train Loss: 0.0001 | Test Loss: 0.0002 | LR: 0.001000 | Time: 0.16 sec\n",
      "Epoch 1139 | Train Loss: 0.0001 | Test Loss: 0.0002 | LR: 0.001000 | Time: 0.14 sec\n",
      "Epoch 1140 | Train Loss: 0.0001 | Test Loss: 0.0002 | LR: 0.001000 | Time: 0.15 sec\n",
      "New best model found at epoch 1140, saving checkpoint...\n",
      "Epoch 1141 | Train Loss: 0.0001 | Test Loss: 0.0002 | LR: 0.001000 | Time: 0.13 sec\n",
      "Epoch 1142 | Train Loss: 0.0001 | Test Loss: 0.0002 | LR: 0.001000 | Time: 0.15 sec\n",
      "Epoch 1143 | Train Loss: 0.0001 | Test Loss: 0.0002 | LR: 0.001000 | Time: 0.16 sec\n",
      "Epoch 1144 | Train Loss: 0.0001 | Test Loss: 0.0002 | LR: 0.001000 | Time: 0.15 sec\n",
      "Epoch 1145 | Train Loss: 0.0001 | Test Loss: 0.0002 | LR: 0.001000 | Time: 0.14 sec\n",
      "Epoch 1146 | Train Loss: 0.0001 | Test Loss: 0.0002 | LR: 0.001000 | Time: 0.15 sec\n",
      "Epoch 1147 | Train Loss: 0.0001 | Test Loss: 0.0002 | LR: 0.000500 | Time: 0.14 sec\n",
      "Epoch 1148 | Train Loss: 0.0001 | Test Loss: 0.0002 | LR: 0.000500 | Time: 0.16 sec\n",
      "Epoch 1149 | Train Loss: 0.0001 | Test Loss: 0.0002 | LR: 0.000500 | Time: 0.18 sec\n",
      "New best model found at epoch 1149, saving checkpoint...\n",
      "Epoch 1150 | Train Loss: 0.0001 | Test Loss: 0.0002 | LR: 0.000500 | Time: 0.15 sec\n",
      "New best model found at epoch 1150, saving checkpoint...\n",
      "Epoch 1151 | Train Loss: 0.0001 | Test Loss: 0.0002 | LR: 0.000500 | Time: 0.15 sec\n",
      "New best model found at epoch 1151, saving checkpoint...\n",
      "Epoch 1152 | Train Loss: 0.0001 | Test Loss: 0.0002 | LR: 0.000500 | Time: 0.16 sec\n",
      "New best model found at epoch 1152, saving checkpoint...\n",
      "Epoch 1153 | Train Loss: 0.0001 | Test Loss: 0.0002 | LR: 0.000500 | Time: 0.14 sec\n",
      "Epoch 1154 | Train Loss: 0.0001 | Test Loss: 0.0002 | LR: 0.000500 | Time: 0.15 sec\n",
      "New best model found at epoch 1154, saving checkpoint...\n",
      "Epoch 1155 | Train Loss: 0.0001 | Test Loss: 0.0002 | LR: 0.000500 | Time: 0.14 sec\n",
      "Epoch 1156 | Train Loss: 0.0001 | Test Loss: 0.0002 | LR: 0.000500 | Time: 0.15 sec\n",
      "Epoch 1157 | Train Loss: 0.0001 | Test Loss: 0.0002 | LR: 0.000500 | Time: 0.14 sec\n",
      "New best model found at epoch 1157, saving checkpoint...\n",
      "Epoch 1158 | Train Loss: 0.0001 | Test Loss: 0.0002 | LR: 0.000500 | Time: 0.16 sec\n",
      "New best model found at epoch 1158, saving checkpoint...\n",
      "Epoch 1159 | Train Loss: 0.0001 | Test Loss: 0.0002 | LR: 0.000500 | Time: 0.16 sec\n",
      "New best model found at epoch 1159, saving checkpoint...\n",
      "Epoch 1160 | Train Loss: 0.0001 | Test Loss: 0.0002 | LR: 0.000500 | Time: 0.15 sec\n",
      "Epoch 1161 | Train Loss: 0.0001 | Test Loss: 0.0002 | LR: 0.000500 | Time: 0.16 sec\n",
      "New best model found at epoch 1161, saving checkpoint...\n",
      "Epoch 1162 | Train Loss: 0.0001 | Test Loss: 0.0002 | LR: 0.000500 | Time: 0.14 sec\n",
      "New best model found at epoch 1162, saving checkpoint...\n",
      "Epoch 1163 | Train Loss: 0.0001 | Test Loss: 0.0002 | LR: 0.000500 | Time: 0.14 sec\n",
      "New best model found at epoch 1163, saving checkpoint...\n",
      "Epoch 1164 | Train Loss: 0.0001 | Test Loss: 0.0002 | LR: 0.000500 | Time: 0.14 sec\n",
      "New best model found at epoch 1164, saving checkpoint...\n",
      "Epoch 1165 | Train Loss: 0.0001 | Test Loss: 0.0002 | LR: 0.000500 | Time: 0.15 sec\n",
      "New best model found at epoch 1165, saving checkpoint...\n",
      "Epoch 1166 | Train Loss: 0.0001 | Test Loss: 0.0002 | LR: 0.000500 | Time: 0.16 sec\n",
      "New best model found at epoch 1166, saving checkpoint...\n",
      "Epoch 1167 | Train Loss: 0.0001 | Test Loss: 0.0002 | LR: 0.000500 | Time: 0.14 sec\n",
      "Epoch 1168 | Train Loss: 0.0001 | Test Loss: 0.0002 | LR: 0.000500 | Time: 0.14 sec\n",
      "New best model found at epoch 1168, saving checkpoint...\n",
      "Epoch 1169 | Train Loss: 0.0001 | Test Loss: 0.0002 | LR: 0.000500 | Time: 0.16 sec\n",
      "New best model found at epoch 1169, saving checkpoint...\n",
      "Epoch 1170 | Train Loss: 0.0001 | Test Loss: 0.0002 | LR: 0.000500 | Time: 0.21 sec\n",
      "New best model found at epoch 1170, saving checkpoint...\n",
      "Epoch 1171 | Train Loss: 0.0001 | Test Loss: 0.0002 | LR: 0.000500 | Time: 0.18 sec\n",
      "New best model found at epoch 1171, saving checkpoint...\n",
      "Epoch 1172 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000500 | Time: 0.14 sec\n",
      "New best model found at epoch 1172, saving checkpoint...\n",
      "Epoch 1173 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000500 | Time: 0.14 sec\n",
      "New best model found at epoch 1173, saving checkpoint...\n",
      "Epoch 1174 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000500 | Time: 0.16 sec\n",
      "New best model found at epoch 1174, saving checkpoint...\n",
      "Epoch 1175 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000500 | Time: 0.15 sec\n",
      "New best model found at epoch 1175, saving checkpoint...\n",
      "Epoch 1176 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000500 | Time: 0.29 sec\n",
      "New best model found at epoch 1176, saving checkpoint...\n",
      "Epoch 1177 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000500 | Time: 0.18 sec\n",
      "New best model found at epoch 1177, saving checkpoint...\n",
      "Epoch 1178 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000500 | Time: 0.18 sec\n",
      "Epoch 1179 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000500 | Time: 0.14 sec\n",
      "New best model found at epoch 1179, saving checkpoint...\n",
      "Epoch 1180 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000500 | Time: 0.16 sec\n",
      "New best model found at epoch 1180, saving checkpoint...\n",
      "Epoch 1181 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000500 | Time: 0.15 sec\n",
      "New best model found at epoch 1181, saving checkpoint...\n",
      "Epoch 1182 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000500 | Time: 0.16 sec\n",
      "Epoch 1183 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000500 | Time: 0.15 sec\n",
      "New best model found at epoch 1183, saving checkpoint...\n",
      "Epoch 1184 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000500 | Time: 0.16 sec\n",
      "Epoch 1185 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000500 | Time: 0.15 sec\n",
      "Epoch 1186 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000500 | Time: 0.15 sec\n",
      "Epoch 1187 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000500 | Time: 0.17 sec\n",
      "New best model found at epoch 1187, saving checkpoint...\n",
      "Epoch 1188 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000500 | Time: 0.21 sec\n",
      "New best model found at epoch 1188, saving checkpoint...\n",
      "Epoch 1189 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000500 | Time: 0.20 sec\n",
      "New best model found at epoch 1189, saving checkpoint...\n",
      "Epoch 1190 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000500 | Time: 0.14 sec\n",
      "New best model found at epoch 1190, saving checkpoint...\n",
      "Epoch 1191 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000500 | Time: 0.15 sec\n",
      "New best model found at epoch 1191, saving checkpoint...\n",
      "Epoch 1192 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000500 | Time: 0.14 sec\n",
      "New best model found at epoch 1192, saving checkpoint...\n",
      "Epoch 1193 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000500 | Time: 0.15 sec\n",
      "New best model found at epoch 1193, saving checkpoint...\n",
      "Epoch 1194 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000500 | Time: 0.14 sec\n",
      "Epoch 1195 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000500 | Time: 0.15 sec\n",
      "New best model found at epoch 1195, saving checkpoint...\n",
      "Epoch 1196 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000500 | Time: 0.15 sec\n",
      "Epoch 1197 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000500 | Time: 0.17 sec\n",
      "New best model found at epoch 1197, saving checkpoint...\n",
      "Epoch 1198 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000500 | Time: 0.23 sec\n",
      "New best model found at epoch 1198, saving checkpoint...\n",
      "Epoch 1199 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000500 | Time: 0.16 sec\n",
      "Epoch 1200 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000500 | Time: 0.14 sec\n",
      "Epoch 1201 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000500 | Time: 0.16 sec\n",
      "New best model found at epoch 1201, saving checkpoint...\n",
      "Epoch 1202 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000500 | Time: 0.16 sec\n",
      "New best model found at epoch 1202, saving checkpoint...\n",
      "Epoch 1203 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000500 | Time: 0.15 sec\n",
      "Epoch 1204 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000500 | Time: 0.23 sec\n",
      "New best model found at epoch 1204, saving checkpoint...\n",
      "Epoch 1205 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000500 | Time: 0.17 sec\n",
      "New best model found at epoch 1205, saving checkpoint...\n",
      "Epoch 1206 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000500 | Time: 0.14 sec\n",
      "New best model found at epoch 1206, saving checkpoint...\n",
      "Epoch 1207 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000500 | Time: 0.16 sec\n",
      "New best model found at epoch 1207, saving checkpoint...\n",
      "Epoch 1208 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000500 | Time: 0.16 sec\n",
      "New best model found at epoch 1208, saving checkpoint...\n",
      "Epoch 1209 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000500 | Time: 0.16 sec\n",
      "Epoch 1210 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000500 | Time: 0.15 sec\n",
      "New best model found at epoch 1210, saving checkpoint...\n",
      "Epoch 1211 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000500 | Time: 0.15 sec\n",
      "Epoch 1212 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000500 | Time: 0.17 sec\n",
      "Epoch 1213 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000500 | Time: 0.17 sec\n",
      "New best model found at epoch 1213, saving checkpoint...\n",
      "Epoch 1214 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000500 | Time: 0.16 sec\n",
      "Epoch 1215 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000500 | Time: 0.15 sec\n",
      "Epoch 1216 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000500 | Time: 0.15 sec\n",
      "New best model found at epoch 1216, saving checkpoint...\n",
      "Epoch 1217 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000500 | Time: 0.14 sec\n",
      "New best model found at epoch 1217, saving checkpoint...\n",
      "Epoch 1218 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000500 | Time: 0.17 sec\n",
      "New best model found at epoch 1218, saving checkpoint...\n",
      "Epoch 1219 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000500 | Time: 0.19 sec\n",
      "Epoch 1220 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000500 | Time: 0.16 sec\n",
      "New best model found at epoch 1220, saving checkpoint...\n",
      "Epoch 1221 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000500 | Time: 0.16 sec\n",
      "Epoch 1222 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000500 | Time: 0.18 sec\n",
      "New best model found at epoch 1222, saving checkpoint...\n",
      "Epoch 1223 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000500 | Time: 0.16 sec\n",
      "New best model found at epoch 1223, saving checkpoint...\n",
      "Epoch 1224 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000500 | Time: 0.15 sec\n",
      "New best model found at epoch 1224, saving checkpoint...\n",
      "Epoch 1225 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000500 | Time: 0.15 sec\n",
      "New best model found at epoch 1225, saving checkpoint...\n",
      "Epoch 1226 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000500 | Time: 0.16 sec\n",
      "New best model found at epoch 1226, saving checkpoint...\n",
      "Epoch 1227 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000500 | Time: 0.15 sec\n",
      "New best model found at epoch 1227, saving checkpoint...\n",
      "Epoch 1228 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000500 | Time: 0.23 sec\n",
      "Epoch 1229 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000500 | Time: 0.16 sec\n",
      "New best model found at epoch 1229, saving checkpoint...\n",
      "Epoch 1230 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000500 | Time: 0.16 sec\n",
      "New best model found at epoch 1230, saving checkpoint...\n",
      "Epoch 1231 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000500 | Time: 0.16 sec\n",
      "New best model found at epoch 1231, saving checkpoint...\n",
      "Epoch 1232 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000500 | Time: 0.19 sec\n",
      "New best model found at epoch 1232, saving checkpoint...\n",
      "Epoch 1233 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000500 | Time: 0.16 sec\n",
      "New best model found at epoch 1233, saving checkpoint...\n",
      "Epoch 1234 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000500 | Time: 0.18 sec\n",
      "New best model found at epoch 1234, saving checkpoint...\n",
      "Epoch 1235 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000500 | Time: 0.15 sec\n",
      "Epoch 1236 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000500 | Time: 0.15 sec\n",
      "Epoch 1237 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000500 | Time: 0.15 sec\n",
      "Epoch 1238 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000500 | Time: 0.16 sec\n",
      "New best model found at epoch 1238, saving checkpoint...\n",
      "Epoch 1239 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000500 | Time: 0.16 sec\n",
      "New best model found at epoch 1239, saving checkpoint...\n",
      "Epoch 1240 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000500 | Time: 0.15 sec\n",
      "New best model found at epoch 1240, saving checkpoint...\n",
      "Epoch 1241 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000500 | Time: 0.16 sec\n",
      "New best model found at epoch 1241, saving checkpoint...\n",
      "Epoch 1242 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000500 | Time: 0.15 sec\n",
      "New best model found at epoch 1242, saving checkpoint...\n",
      "Epoch 1243 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000500 | Time: 0.15 sec\n",
      "Epoch 1244 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000500 | Time: 0.16 sec\n",
      "New best model found at epoch 1244, saving checkpoint...\n",
      "Epoch 1245 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000500 | Time: 0.15 sec\n",
      "Epoch 1246 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000500 | Time: 0.17 sec\n",
      "New best model found at epoch 1246, saving checkpoint...\n",
      "Epoch 1247 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000500 | Time: 0.15 sec\n",
      "New best model found at epoch 1247, saving checkpoint...\n",
      "Epoch 1248 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000500 | Time: 0.16 sec\n",
      "New best model found at epoch 1248, saving checkpoint...\n",
      "Epoch 1249 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000500 | Time: 0.14 sec\n",
      "New best model found at epoch 1249, saving checkpoint...\n",
      "Epoch 1250 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000500 | Time: 0.16 sec\n",
      "Epoch 1251 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000500 | Time: 0.15 sec\n",
      "Epoch 1252 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000500 | Time: 0.16 sec\n",
      "Epoch 1253 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000500 | Time: 0.16 sec\n",
      "Epoch 1254 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000500 | Time: 0.16 sec\n",
      "Epoch 1255 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000500 | Time: 0.16 sec\n",
      "Epoch 1256 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.17 sec\n",
      "Epoch 1257 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.17 sec\n",
      "New best model found at epoch 1257, saving checkpoint...\n",
      "Epoch 1258 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.16 sec\n",
      "New best model found at epoch 1258, saving checkpoint...\n",
      "Epoch 1259 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.15 sec\n",
      "Epoch 1260 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.16 sec\n",
      "Epoch 1261 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.16 sec\n",
      "Epoch 1262 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.17 sec\n",
      "New best model found at epoch 1262, saving checkpoint...\n",
      "Epoch 1263 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.15 sec\n",
      "New best model found at epoch 1263, saving checkpoint...\n",
      "Epoch 1264 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.15 sec\n",
      "New best model found at epoch 1264, saving checkpoint...\n",
      "Epoch 1265 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.18 sec\n",
      "New best model found at epoch 1265, saving checkpoint...\n",
      "Epoch 1266 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.16 sec\n",
      "Epoch 1267 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.16 sec\n",
      "New best model found at epoch 1267, saving checkpoint...\n",
      "Epoch 1268 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.16 sec\n",
      "Epoch 1269 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.17 sec\n",
      "New best model found at epoch 1269, saving checkpoint...\n",
      "Epoch 1270 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.16 sec\n",
      "New best model found at epoch 1270, saving checkpoint...\n",
      "Epoch 1271 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.15 sec\n",
      "New best model found at epoch 1271, saving checkpoint...\n",
      "Epoch 1272 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.17 sec\n",
      "Epoch 1273 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.17 sec\n",
      "New best model found at epoch 1273, saving checkpoint...\n",
      "Epoch 1274 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.16 sec\n",
      "New best model found at epoch 1274, saving checkpoint...\n",
      "Epoch 1275 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.17 sec\n",
      "Epoch 1276 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.16 sec\n",
      "New best model found at epoch 1276, saving checkpoint...\n",
      "Epoch 1277 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.16 sec\n",
      "Epoch 1278 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.15 sec\n",
      "Epoch 1279 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.15 sec\n",
      "New best model found at epoch 1279, saving checkpoint...\n",
      "Epoch 1280 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.18 sec\n",
      "Epoch 1281 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.16 sec\n",
      "New best model found at epoch 1281, saving checkpoint...\n",
      "Epoch 1282 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.16 sec\n",
      "New best model found at epoch 1282, saving checkpoint...\n",
      "Epoch 1283 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.15 sec\n",
      "Epoch 1284 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.16 sec\n",
      "New best model found at epoch 1284, saving checkpoint...\n",
      "Epoch 1285 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.16 sec\n",
      "New best model found at epoch 1285, saving checkpoint...\n",
      "Epoch 1286 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.15 sec\n",
      "New best model found at epoch 1286, saving checkpoint...\n",
      "Epoch 1287 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.16 sec\n",
      "New best model found at epoch 1287, saving checkpoint...\n",
      "Epoch 1288 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.19 sec\n",
      "Epoch 1289 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.18 sec\n",
      "New best model found at epoch 1289, saving checkpoint...\n",
      "Epoch 1290 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.15 sec\n",
      "Epoch 1291 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.16 sec\n",
      "New best model found at epoch 1291, saving checkpoint...\n",
      "Epoch 1292 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.15 sec\n",
      "New best model found at epoch 1292, saving checkpoint...\n",
      "Epoch 1293 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.17 sec\n",
      "New best model found at epoch 1293, saving checkpoint...\n",
      "Epoch 1294 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.15 sec\n",
      "New best model found at epoch 1294, saving checkpoint...\n",
      "Epoch 1295 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.17 sec\n",
      "New best model found at epoch 1295, saving checkpoint...\n",
      "Epoch 1296 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.18 sec\n",
      "New best model found at epoch 1296, saving checkpoint...\n",
      "Epoch 1297 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.16 sec\n",
      "Epoch 1298 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.16 sec\n",
      "New best model found at epoch 1298, saving checkpoint...\n",
      "Epoch 1299 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.16 sec\n",
      "New best model found at epoch 1299, saving checkpoint...\n",
      "Epoch 1300 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.17 sec\n",
      "Epoch 1301 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.17 sec\n",
      "New best model found at epoch 1301, saving checkpoint...\n",
      "Epoch 1302 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.17 sec\n",
      "Epoch 1303 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.16 sec\n",
      "Epoch 1304 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.17 sec\n",
      "New best model found at epoch 1304, saving checkpoint...\n",
      "Epoch 1305 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.15 sec\n",
      "New best model found at epoch 1305, saving checkpoint...\n",
      "Epoch 1306 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.15 sec\n",
      "Epoch 1307 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.15 sec\n",
      "New best model found at epoch 1307, saving checkpoint...\n",
      "Epoch 1308 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.15 sec\n",
      "New best model found at epoch 1308, saving checkpoint...\n",
      "Epoch 1309 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.16 sec\n",
      "New best model found at epoch 1309, saving checkpoint...\n",
      "Epoch 1310 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.16 sec\n",
      "New best model found at epoch 1310, saving checkpoint...\n",
      "Epoch 1311 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.15 sec\n",
      "Epoch 1312 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.15 sec\n",
      "New best model found at epoch 1312, saving checkpoint...\n",
      "Epoch 1313 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.15 sec\n",
      "New best model found at epoch 1313, saving checkpoint...\n",
      "Epoch 1314 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.16 sec\n",
      "New best model found at epoch 1314, saving checkpoint...\n",
      "Epoch 1315 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.15 sec\n",
      "Epoch 1316 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.15 sec\n",
      "Epoch 1317 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.16 sec\n",
      "New best model found at epoch 1317, saving checkpoint...\n",
      "Epoch 1318 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.16 sec\n",
      "New best model found at epoch 1318, saving checkpoint...\n",
      "Epoch 1319 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.17 sec\n",
      "Epoch 1320 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.16 sec\n",
      "Epoch 1321 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.16 sec\n",
      "New best model found at epoch 1321, saving checkpoint...\n",
      "Epoch 1322 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.16 sec\n",
      "Epoch 1323 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.18 sec\n",
      "New best model found at epoch 1323, saving checkpoint...\n",
      "Epoch 1324 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.19 sec\n",
      "Epoch 1325 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.17 sec\n",
      "Epoch 1326 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.15 sec\n",
      "New best model found at epoch 1326, saving checkpoint...\n",
      "Epoch 1327 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.16 sec\n",
      "Epoch 1328 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.15 sec\n",
      "New best model found at epoch 1328, saving checkpoint...\n",
      "Epoch 1329 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.16 sec\n",
      "New best model found at epoch 1329, saving checkpoint...\n",
      "Epoch 1330 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.16 sec\n",
      "Epoch 1331 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.17 sec\n",
      "New best model found at epoch 1331, saving checkpoint...\n",
      "Epoch 1332 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.16 sec\n",
      "New best model found at epoch 1332, saving checkpoint...\n",
      "Epoch 1333 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.17 sec\n",
      "Epoch 1334 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.17 sec\n",
      "New best model found at epoch 1334, saving checkpoint...\n",
      "Epoch 1335 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.17 sec\n",
      "New best model found at epoch 1335, saving checkpoint...\n",
      "Epoch 1336 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.16 sec\n",
      "Epoch 1337 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.17 sec\n",
      "Epoch 1338 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.17 sec\n",
      "New best model found at epoch 1338, saving checkpoint...\n",
      "Epoch 1339 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.16 sec\n",
      "Epoch 1340 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.15 sec\n",
      "New best model found at epoch 1340, saving checkpoint...\n",
      "Epoch 1341 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.17 sec\n",
      "New best model found at epoch 1341, saving checkpoint...\n",
      "Epoch 1342 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.16 sec\n",
      "New best model found at epoch 1342, saving checkpoint...\n",
      "Epoch 1343 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.18 sec\n",
      "Epoch 1344 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.16 sec\n",
      "New best model found at epoch 1344, saving checkpoint...\n",
      "Epoch 1345 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.17 sec\n",
      "Epoch 1346 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.17 sec\n",
      "Epoch 1347 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.18 sec\n",
      "Epoch 1348 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.17 sec\n",
      "New best model found at epoch 1348, saving checkpoint...\n",
      "Epoch 1349 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.19 sec\n",
      "New best model found at epoch 1349, saving checkpoint...\n",
      "Epoch 1350 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.17 sec\n",
      "New best model found at epoch 1350, saving checkpoint...\n",
      "Epoch 1351 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.17 sec\n",
      "New best model found at epoch 1351, saving checkpoint...\n",
      "Epoch 1352 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.19 sec\n",
      "New best model found at epoch 1352, saving checkpoint...\n",
      "Epoch 1353 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.21 sec\n",
      "Epoch 1354 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.16 sec\n",
      "New best model found at epoch 1354, saving checkpoint...\n",
      "Epoch 1355 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.21 sec\n",
      "New best model found at epoch 1355, saving checkpoint...\n",
      "Epoch 1356 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.22 sec\n",
      "New best model found at epoch 1356, saving checkpoint...\n",
      "Epoch 1357 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.22 sec\n",
      "Epoch 1358 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.18 sec\n",
      "New best model found at epoch 1358, saving checkpoint...\n",
      "Epoch 1359 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.15 sec\n",
      "New best model found at epoch 1359, saving checkpoint...\n",
      "Epoch 1360 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.23 sec\n",
      "New best model found at epoch 1360, saving checkpoint...\n",
      "Epoch 1361 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.18 sec\n",
      "New best model found at epoch 1361, saving checkpoint...\n",
      "Epoch 1362 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.18 sec\n",
      "Epoch 1363 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.18 sec\n",
      "New best model found at epoch 1363, saving checkpoint...\n",
      "Epoch 1364 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.16 sec\n",
      "New best model found at epoch 1364, saving checkpoint...\n",
      "Epoch 1365 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.16 sec\n",
      "Epoch 1366 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.19 sec\n",
      "New best model found at epoch 1366, saving checkpoint...\n",
      "Epoch 1367 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.16 sec\n",
      "New best model found at epoch 1367, saving checkpoint...\n",
      "Epoch 1368 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.17 sec\n",
      "New best model found at epoch 1368, saving checkpoint...\n",
      "Epoch 1369 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.17 sec\n",
      "New best model found at epoch 1369, saving checkpoint...\n",
      "Epoch 1370 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.19 sec\n",
      "Epoch 1371 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.19 sec\n",
      "Epoch 1372 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.32 sec\n",
      "Epoch 1373 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.36 sec\n",
      "New best model found at epoch 1373, saving checkpoint...\n",
      "Epoch 1374 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.21 sec\n",
      "New best model found at epoch 1374, saving checkpoint...\n",
      "Epoch 1375 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.17 sec\n",
      "New best model found at epoch 1375, saving checkpoint...\n",
      "Epoch 1376 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.16 sec\n",
      "Epoch 1377 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.19 sec\n",
      "New best model found at epoch 1377, saving checkpoint...\n",
      "Epoch 1378 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.18 sec\n",
      "New best model found at epoch 1378, saving checkpoint...\n",
      "Epoch 1379 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.17 sec\n",
      "Epoch 1380 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.17 sec\n",
      "Epoch 1381 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.18 sec\n",
      "Epoch 1382 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.16 sec\n",
      "New best model found at epoch 1382, saving checkpoint...\n",
      "Epoch 1383 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.17 sec\n",
      "Epoch 1384 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.16 sec\n",
      "New best model found at epoch 1384, saving checkpoint...\n",
      "Epoch 1385 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.19 sec\n",
      "Epoch 1386 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.16 sec\n",
      "Epoch 1387 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.17 sec\n",
      "Epoch 1388 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.16 sec\n",
      "New best model found at epoch 1388, saving checkpoint...\n",
      "Epoch 1389 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.18 sec\n",
      "New best model found at epoch 1389, saving checkpoint...\n",
      "Epoch 1390 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.19 sec\n",
      "New best model found at epoch 1390, saving checkpoint...\n",
      "Epoch 1391 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.16 sec\n",
      "Epoch 1392 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.19 sec\n",
      "New best model found at epoch 1392, saving checkpoint...\n",
      "Epoch 1393 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.18 sec\n",
      "New best model found at epoch 1393, saving checkpoint...\n",
      "Epoch 1394 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.19 sec\n",
      "Epoch 1395 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.28 sec\n",
      "New best model found at epoch 1395, saving checkpoint...\n",
      "Epoch 1396 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.17 sec\n",
      "New best model found at epoch 1396, saving checkpoint...\n",
      "Epoch 1397 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.18 sec\n",
      "New best model found at epoch 1397, saving checkpoint...\n",
      "Epoch 1398 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.18 sec\n",
      "New best model found at epoch 1398, saving checkpoint...\n",
      "Epoch 1399 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.16 sec\n",
      "Epoch 1400 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.17 sec\n",
      "Epoch 1401 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.18 sec\n",
      "New best model found at epoch 1401, saving checkpoint...\n",
      "Epoch 1402 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.19 sec\n",
      "Epoch 1403 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.26 sec\n",
      "Epoch 1404 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.18 sec\n",
      "Epoch 1405 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.17 sec\n",
      "New best model found at epoch 1405, saving checkpoint...\n",
      "Epoch 1406 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.16 sec\n",
      "New best model found at epoch 1406, saving checkpoint...\n",
      "Epoch 1407 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.16 sec\n",
      "New best model found at epoch 1407, saving checkpoint...\n",
      "Epoch 1408 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.22 sec\n",
      "New best model found at epoch 1408, saving checkpoint...\n",
      "Epoch 1409 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.21 sec\n",
      "New best model found at epoch 1409, saving checkpoint...\n",
      "Epoch 1410 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.18 sec\n",
      "Epoch 1411 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.18 sec\n",
      "New best model found at epoch 1411, saving checkpoint...\n",
      "Epoch 1412 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.17 sec\n",
      "New best model found at epoch 1412, saving checkpoint...\n",
      "Epoch 1413 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.17 sec\n",
      "New best model found at epoch 1413, saving checkpoint...\n",
      "Epoch 1414 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.19 sec\n",
      "New best model found at epoch 1414, saving checkpoint...\n",
      "Epoch 1415 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.17 sec\n",
      "New best model found at epoch 1415, saving checkpoint...\n",
      "Epoch 1416 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.19 sec\n",
      "New best model found at epoch 1416, saving checkpoint...\n",
      "Epoch 1417 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.18 sec\n",
      "New best model found at epoch 1417, saving checkpoint...\n",
      "Epoch 1418 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.17 sec\n",
      "Epoch 1419 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.18 sec\n",
      "New best model found at epoch 1419, saving checkpoint...\n",
      "Epoch 1420 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.17 sec\n",
      "New best model found at epoch 1420, saving checkpoint...\n",
      "Epoch 1421 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.20 sec\n",
      "New best model found at epoch 1421, saving checkpoint...\n",
      "Epoch 1422 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.18 sec\n",
      "Epoch 1423 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.17 sec\n",
      "Epoch 1424 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.18 sec\n",
      "Epoch 1425 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.17 sec\n",
      "New best model found at epoch 1425, saving checkpoint...\n",
      "Epoch 1426 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.17 sec\n",
      "New best model found at epoch 1426, saving checkpoint...\n",
      "Epoch 1427 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.18 sec\n",
      "New best model found at epoch 1427, saving checkpoint...\n",
      "Epoch 1428 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.19 sec\n",
      "New best model found at epoch 1428, saving checkpoint...\n",
      "Epoch 1429 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.19 sec\n",
      "Epoch 1430 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.17 sec\n",
      "Epoch 1431 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.18 sec\n",
      "Epoch 1432 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.18 sec\n",
      "Epoch 1433 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.17 sec\n",
      "Epoch 1434 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.26 sec\n",
      "New best model found at epoch 1434, saving checkpoint...\n",
      "Epoch 1435 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.17 sec\n",
      "New best model found at epoch 1435, saving checkpoint...\n",
      "Epoch 1436 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.19 sec\n",
      "New best model found at epoch 1436, saving checkpoint...\n",
      "Epoch 1437 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.18 sec\n",
      "New best model found at epoch 1437, saving checkpoint...\n",
      "Epoch 1438 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.19 sec\n",
      "Epoch 1439 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.18 sec\n",
      "Epoch 1440 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.16 sec\n",
      "Epoch 1441 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.18 sec\n",
      "New best model found at epoch 1441, saving checkpoint...\n",
      "Epoch 1442 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.17 sec\n",
      "Epoch 1443 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.18 sec\n",
      "Epoch 1444 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.18 sec\n",
      "Epoch 1445 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.17 sec\n",
      "Epoch 1446 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.18 sec\n",
      "Epoch 1447 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.17 sec\n",
      "New best model found at epoch 1447, saving checkpoint...\n",
      "Epoch 1448 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.18 sec\n",
      "New best model found at epoch 1448, saving checkpoint...\n",
      "Epoch 1449 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.19 sec\n",
      "New best model found at epoch 1449, saving checkpoint...\n",
      "Epoch 1450 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.23 sec\n",
      "New best model found at epoch 1450, saving checkpoint...\n",
      "Epoch 1451 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.18 sec\n",
      "Epoch 1452 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.18 sec\n",
      "New best model found at epoch 1452, saving checkpoint...\n",
      "Epoch 1453 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.19 sec\n",
      "Epoch 1454 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.20 sec\n",
      "Epoch 1455 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.19 sec\n",
      "Epoch 1456 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.20 sec\n",
      "Epoch 1457 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.17 sec\n",
      "New best model found at epoch 1457, saving checkpoint...\n",
      "Epoch 1458 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.20 sec\n",
      "New best model found at epoch 1458, saving checkpoint...\n",
      "Epoch 1459 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.18 sec\n",
      "Epoch 1460 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.17 sec\n",
      "Epoch 1461 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.19 sec\n",
      "New best model found at epoch 1461, saving checkpoint...\n",
      "Epoch 1462 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.17 sec\n",
      "Epoch 1463 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.16 sec\n",
      "Epoch 1464 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.17 sec\n",
      "New best model found at epoch 1464, saving checkpoint...\n",
      "Epoch 1465 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.20 sec\n",
      "New best model found at epoch 1465, saving checkpoint...\n",
      "Epoch 1466 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.19 sec\n",
      "New best model found at epoch 1466, saving checkpoint...\n",
      "Epoch 1467 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.18 sec\n",
      "Epoch 1468 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.20 sec\n",
      "Epoch 1469 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.18 sec\n",
      "Epoch 1470 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.20 sec\n",
      "Epoch 1471 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.17 sec\n",
      "Epoch 1472 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000250 | Time: 0.17 sec\n",
      "Epoch 1473 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000125 | Time: 0.18 sec\n",
      "New best model found at epoch 1473, saving checkpoint...\n",
      "Epoch 1474 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000125 | Time: 0.17 sec\n",
      "New best model found at epoch 1474, saving checkpoint...\n",
      "Epoch 1475 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000125 | Time: 0.20 sec\n",
      "New best model found at epoch 1475, saving checkpoint...\n",
      "Epoch 1476 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000125 | Time: 0.18 sec\n",
      "Epoch 1477 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000125 | Time: 0.21 sec\n",
      "Epoch 1478 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000125 | Time: 0.19 sec\n",
      "New best model found at epoch 1478, saving checkpoint...\n",
      "Epoch 1479 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000125 | Time: 0.16 sec\n",
      "New best model found at epoch 1479, saving checkpoint...\n",
      "Epoch 1480 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000125 | Time: 0.17 sec\n",
      "New best model found at epoch 1480, saving checkpoint...\n",
      "Epoch 1481 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000125 | Time: 0.18 sec\n",
      "Epoch 1482 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000125 | Time: 0.18 sec\n",
      "Epoch 1483 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000125 | Time: 0.19 sec\n",
      "Epoch 1484 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000125 | Time: 0.18 sec\n",
      "Epoch 1485 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000125 | Time: 0.18 sec\n",
      "Epoch 1486 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000125 | Time: 0.18 sec\n",
      "New best model found at epoch 1486, saving checkpoint...\n",
      "Epoch 1487 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000125 | Time: 0.17 sec\n",
      "New best model found at epoch 1487, saving checkpoint...\n",
      "Epoch 1488 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000125 | Time: 0.18 sec\n",
      "Epoch 1489 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000125 | Time: 0.17 sec\n",
      "Epoch 1490 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000125 | Time: 0.17 sec\n",
      "New best model found at epoch 1490, saving checkpoint...\n",
      "Epoch 1491 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000125 | Time: 0.19 sec\n",
      "New best model found at epoch 1491, saving checkpoint...\n",
      "Epoch 1492 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000125 | Time: 0.17 sec\n",
      "New best model found at epoch 1492, saving checkpoint...\n",
      "Epoch 1493 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000125 | Time: 0.20 sec\n",
      "New best model found at epoch 1493, saving checkpoint...\n",
      "Epoch 1494 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000125 | Time: 0.27 sec\n",
      "New best model found at epoch 1494, saving checkpoint...\n",
      "Epoch 1495 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000125 | Time: 0.17 sec\n",
      "New best model found at epoch 1495, saving checkpoint...\n",
      "Epoch 1496 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000125 | Time: 0.18 sec\n",
      "Epoch 1497 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000125 | Time: 0.17 sec\n",
      "New best model found at epoch 1497, saving checkpoint...\n",
      "Epoch 1498 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000125 | Time: 0.19 sec\n",
      "Epoch 1499 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000125 | Time: 0.20 sec\n",
      "Epoch 1500 | Train Loss: 0.0001 | Test Loss: 0.0001 | LR: 0.000125 | Time: 0.20 sec\n",
      "New best model found at epoch 1500, saving checkpoint...\n"
     ]
    }
   ],
   "source": [
    "#Training loop\n",
    "# Prepare training and test datasets\n",
    "train_ds = TitanicAutoencoderDataset(X_train)\n",
    "test_ds = TitanicAutoencoderDataset(X_test)\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, num_workers=WORKERS, shuffle=True)\n",
    "test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE, num_workers=WORKERS)\n",
    "\n",
    "# Track losses\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "best_loss = float('inf') # Initialize best_loss for comparison and checkpointing\n",
    "# Training loop\n",
    "num_epochs = 1500\n",
    "for epoch in range(start_epoch, num_epochs):\n",
    "    start_time = time.time()\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "\n",
    "    for x, y in train_loader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        recon = model(x)\n",
    "        loss = loss_fn(recon, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "    train_losses.append(avg_train_loss)\n",
    "\n",
    "    end_time = time.time()\n",
    "    epoch_duration = end_time - start_time\n",
    "    # GPU metrics\n",
    "    gpu_alloc = torch.cuda.memory_allocated() / 1024**2 # Convert to MB\n",
    "    gpu_reserved = torch.cuda.memory_reserved() / 1024**2 # Convert to MB\n",
    "    writer.add_scalar(\"GPU/Memory_Allocated_MB\", gpu_alloc, epoch)\n",
    "    writer.add_scalar(\"GPU/Memory_Reserved_MB\", gpu_reserved, epoch)\n",
    "\n",
    "    try:\n",
    "        gpu_util, mem_used = get_gpu_utilization()\n",
    "        writer.add_scalar(\"GPU/Utilization_%\", gpu_util, epoch)\n",
    "        writer.add_scalar(\"GPU/Memory_Used_MB\", mem_used, epoch)\n",
    "    except:\n",
    "        pass  # In case nvidia-smi isn't available\n",
    "\n",
    "    # Evaluate on test set\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for x, y in test_loader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            recon = model(x)\n",
    "            loss = loss_fn(recon, y)\n",
    "            test_loss += loss.item()\n",
    "\n",
    "    avg_test_loss = test_loss / len(test_loader)\n",
    "    test_losses.append(avg_test_loss)\n",
    "\n",
    "    # ‚úÖ Log scalar losses\n",
    "    writer.add_scalar(\"Loss/train\", avg_train_loss, epoch)\n",
    "    writer.add_scalar(\"Loss/test\", avg_test_loss, epoch)\n",
    "    writer.add_figure(\"Loss Overlap Curve\", plot_loss_curve(train_losses, test_losses), global_step=epoch)\n",
    "\n",
    "    # ‚úÖ Log weights and gradients\n",
    "    for name, param in model.named_parameters():\n",
    "        writer.add_histogram(f\"Weights/{name}\", param, epoch)\n",
    "        if param.grad is not None:\n",
    "            writer.add_histogram(f\"Gradients/{name}\", param.grad, epoch)\n",
    "\n",
    "    # ‚úÖ Log activation from encoder\n",
    "    with torch.no_grad():\n",
    "        activation_sample = torch.tensor(X_train[:1], dtype=torch.float32).to(device)\n",
    "        encoded = model.encoder(activation_sample)\n",
    "        writer.add_histogram(\"Activations/EncoderOutput\", encoded, epoch)\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        writer.add_scalar(\"LR\", current_lr, epoch)\n",
    "\n",
    "    print(f\"Epoch {epoch+1:2d} | Train Loss: {avg_train_loss:.4f} | Test Loss: {avg_test_loss:.4f} | LR: {current_lr:.6f} | Time: {epoch_duration:.2f} sec\")\n",
    "\n",
    "    # Save only the best model based on test loss\n",
    "    if avg_test_loss < best_loss:\n",
    "        best_loss = avg_test_loss\n",
    "        print(f\"New best model found at epoch {epoch+1}, saving checkpoint...\")\n",
    "        \n",
    "            # Save the model state\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'scheduler_state_dict': scheduler.state_dict(),\n",
    "            'train_losses': train_losses,\n",
    "            'test_losses': test_losses,\n",
    "            'input_dim': X_train.shape[1],           # ‚úÖ Save architecture args\n",
    "            'latent_dim': LATENT_DIM \n",
    "            }, f\"{CHECKPOINT_DIR}/autoencoder_epoch{epoch+1}.pt\")\n",
    "    \n",
    "    scheduler.step(avg_test_loss) # Adjust learning rate based on test loss\n",
    "\n",
    "# ‚úÖ After training ‚Äî log embeddings to projector\n",
    "with torch.no_grad():\n",
    "    sample_input = torch.tensor(X_test[:500], dtype=torch.float32).to(device)\n",
    "    latent_vectors = model.encoder(sample_input)\n",
    "    metadata = [f\"Passenger {i}\" for i in range(sample_input.shape[0])]\n",
    "    writer.add_embedding(latent_vectors, metadata=metadata, tag=\"LatentEmbeddings\", global_step=num_epochs)\n",
    "    \n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c1ca37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recmd_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
